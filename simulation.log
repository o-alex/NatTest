[11:12:59,037] INFO  {NatTestLauncher} initiating
[11:12:59,267] INFO  {NatTestLauncher} starting
[11:12:59,362] INFO  {Config} System: seed:-3418128274972233948
[11:12:59,362] INFO  {Config} System: self ip:null port:30000 id:1
[11:12:59,365] INFO  {Config} System: caracal:missing
[11:12:59,365] INFO  {Config} System: aggregator:missing
[11:12:59,366] INFO  {Config} Nat:globalCroupier:0
[11:12:59,373] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:12:59,379] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:12:59,380] INFO  {Config} Nat:croupier bootstrap:[]
[11:12:59,385] INFO  {IpSolverComp} initiating...
[11:12:59,387] INFO  {IpSolverComp} starting...
[11:12:59,388] DEBUG {IpSolverComp} GetIp request
[11:12:59,397] DEBUG {IpSolverComp} GetIp responding
[11:12:59,398] INFO  {NatSetup} received local interfaces:[NI:name:en0 (en0) addr:/193.10.67.178 up:true mtu:1500 netPrefixLength:22, NI:name:lo0 (lo0) addr:/127.0.0.1 up:true mtu:16384 netPrefixLength:8]
[11:12:59,398] INFO  {NatSetup} multiple ips detected, proceeding with:/193.10.67.178
[11:12:59,398] INFO  {NatSetup} starting with local interface:/193.10.67.178
[11:12:59,400] INFO  {Config} Nat:globalCroupier:0
[11:12:59,400] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:12:59,401] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:12:59,401] INFO  {Config} Nat:croupier bootstrap:[]
[11:12:59,411] INFO  {NatDetectionComp} 193.10.67.178:30000<1> initiating...
[11:12:59,412] INFO  {NatDetectionComp} 193.10.67.178:30000<1> starting...
[11:12:59,416] INFO  {StunClientComp} /193.10.67.178<43211,43210> initiating...
[11:12:59,425] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting...
[11:12:59,425] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[11:12:59,426] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[11:12:59,427] INFO  {UpnpComp} nat upnp initiating...
[11:12:59,430] INFO  {UpnpComp} nat upnp starting...
[11:12:59,478] DEBUG {UpnpComp} nat upnp :Device notified:M-SEARCH * HTTP/1.1
ST: upnp:rootdevice
MX: 3
MAN: "ssdp:discover"
HOST: 239.255.255.250:1900


[11:12:59,553] INFO  {SocketUDT} library location : ./lib/bin
[11:12:59,554] INFO  {SocketUDT} loader provider  : com.barchart.udt.lib.LibraryLoaderUDT
[11:12:59,555] INFO  {PluginPropsUDT} ARCH/OS/LINK = x86_64/MacOSX/gpp
[11:12:59,556] INFO  {LibraryLoaderUDT} Platform supported.
[11:12:59,557] INFO  {LibraryLoaderUDT} Loading release libraries.
[11:12:59,678] INFO  {LibraryLoaderUDT} Release libraries loaded.
[11:12:59,686] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[11:12:59,686] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[11:12:59,699] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting new echo session:e57ce054-5483-42f2-8423-68e5ba0aabd9
[11:12:59,701] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server1:193.10.64.107:54321<-1> 193.10.64.107:54320<-1>
[11:12:59,701] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server2:193.10.64.85:54321<-2> 193.10.64.85:54320<-2>
[11:12:59,702] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:SIP_SP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[11:12:59,793] INFO  {NettyNetwork@43211} Successfully bound to ip:port /193.10.67.178:43211
[11:12:59,793] INFO  {NettyNetwork@43210} Successfully bound to ip:port /193.10.67.178:43210
[11:12:59,818] INFO  {NettyNetwork@43211} Successfully bound UDT to ip:port /193.10.67.178:54687 with config: {RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@7dd3130f, WRITE_BUFFER_HIGH_WATER_MARK=65536, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, SO_BACKLOG=64, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@19d744c5, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), SO_SNDBUF=131072, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, AUTO_READ=true, CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_RCVBUF=131072, WRITE_SPIN_COUNT=16, SO_REUSEADDR=true, SO_LINGER=0, MAX_MESSAGES_PER_READ=16}
[11:12:59,818] INFO  {NettyNetwork@43210} Successfully bound UDT to ip:port /193.10.67.178:61386 with config: {RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@7dd3130f, WRITE_BUFFER_HIGH_WATER_MARK=65536, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, SO_BACKLOG=64, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@19d744c5, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), SO_SNDBUF=131072, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, AUTO_READ=true, CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_RCVBUF=131072, WRITE_SPIN_COUNT=16, SO_REUSEADDR=true, SO_LINGER=0, MAX_MESSAGES_PER_READ=16}
[11:12:59,835] INFO  {NettyNetwork@43210} Successfully bound to ip:port /193.10.67.178:43210
[11:12:59,835] TRACE {NettyNetwork@43210} Channel connected: UDP /193.10.67.178:43210 => null ([id: 0x7b15df53, /193.10.67.178:43210])
[11:12:59,835] INFO  {NettyNetwork@43211} Successfully bound to ip:port /193.10.67.178:43211
[11:12:59,835] TRACE {NettyNetwork@43211} Channel connected: UDP /193.10.67.178:43211 => null ([id: 0x966d9ed4, /193.10.67.178:43211])
[11:12:59,868] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicContentMsg, found: 133
[11:12:59,870] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:12:59,870] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@10b8216f for object STUN_ECHO_REQ<SIP_SP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:12:59,871] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedHeader, found: 132
[11:12:59,871] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:12:59,871] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@41339b23 for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@7c7a3d21 (sID : [-124]) .
[11:12:59,871] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicHeader, found: 130
[11:12:59,871] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedAddress, found: 129
[11:12:59,871] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicAddress, found: 128
[11:12:59,875] TRACE {Serializers} Checked rule for class se.sics.nat.stun.msg.StunEcho$Request, found: 135
[11:12:59,875] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:12:59,875] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@631270b for object STUN_ECHO_REQ<SIP_SP> (sID : [-121]) .
[11:12:59,875] TRACE {Serializers} Checked rule for class java.util.UUID, found: 6
[11:12:59,875] DEBUG {NettyNetwork@43211} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@33a414d7 (61bytes)
[11:12:59,899] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:12:59,899] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@10b8216f for buffer with hint {}.
[11:12:59,899] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:12:59,899] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@41339b23 for buffer with hint {}.
[11:12:59,899] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:12:59,899] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@664a132 for buffer with hint Optional.absent().
[11:12:59,900] DEBUG {NettyNetwork@43211} Delivering message STUN_ECHO_RESP<SIP_SP>from:193.10.64.107:54321<-1>to:193.10.67.178:43211<1> from 193.10.64.107:54321<-1> to 193.10.67.178:43211<1> protocol UDP
[11:12:59,900] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<SIP_SP> from:193.10.64.107:54321<-1>
[11:12:59,901] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:DIP_DP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[11:12:59,915] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:12:59,915] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@10b8216f for object STUN_ECHO_REQ<DIP_DP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:12:59,915] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:12:59,915] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@41339b23 for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@7c7a3d21 (sID : [-124]) .
[11:12:59,915] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:12:59,915] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@631270b for object STUN_ECHO_REQ<DIP_DP> (sID : [-121]) .
[11:12:59,916] DEBUG {NettyNetwork@43211} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@3139d8 (72bytes)
[11:12:59,947] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:12:59,947] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@10b8216f for buffer with hint {}.
[11:12:59,948] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:12:59,948] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@41339b23 for buffer with hint {}.
[11:12:59,948] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:12:59,948] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@664a132 for buffer with hint Optional.absent().
[11:12:59,948] DEBUG {NettyNetwork@43211} Delivering message STUN_ECHO_RESP<DIP_DP>from:193.10.64.85:54320<-2>to:193.10.67.178:43211<1> from 193.10.64.85:54320<-2> to 193.10.67.178:43211<1> protocol UDP
[11:12:59,948] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<DIP_DP> from:193.10.64.85:54320<-2>
[11:12:59,949] INFO  {StunClientComp} /193.10.67.178<43211,43210> session result:OPEN
[11:12:59,954] INFO  {NatDetectionComp} 193.10.67.178:30000<1> nat detected:OP public ip:/193.10.67.178
[11:13:00,680] TRACE {Cybergarage} UP&P.getAddress() is called \o/
[11:13:00,680] DEBUG {Cybergarage} No UP&P device found, detection of the external ip address using the plugin has failed
[11:13:00,684] INFO  {NatDetectionComp} 193.10.67.178:30000<1> upnp ready:Optional.absent()
[11:13:00,685] INFO  {NatSetup} nat detected:OP public ip:/193.10.67.178 private ip:/193.10.67.178
[11:13:00,685] DEBUG {NatSetup} Initiating the binding on the socket to keep the port being used by some other service.
[11:13:00,685] DEBUG {NatSetup} Trying to bind on the socket1 with ip: /193.10.67.178 and port: 30000
[11:13:00,690] DEBUG {NatSetup} Socket successfully bound to ip :/193.10.67.178 and port: 30000
[11:13:00,690] DEBUG {NatSetup} {}Building the system configuration.
[11:13:00,695] INFO  {Config} Nat:globalCroupier:0
[11:13:00,695] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:13:00,696] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:13:00,696] INFO  {Config} Nat:croupier bootstrap:[]
[11:13:00,699] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:13:00,710] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[11:13:00,730] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:13:00,740] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[11:13:00,742] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[11:13:00,743] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[11:13:00,744] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[11:13:00,744] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting...
[11:13:00,744] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@78d2c2f
[11:13:00,745] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[11:13:00,745] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:13:00,745] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: se.sics.nat.NatTraverserComp@36cc5582 has no negative se.sics.kompics.network.Network
	at se.sics.kompics.JavaComponent.getNegative(JavaComponent.java:95)
	at se.sics.nat.NatSetup.finish(NatSetup.java:281)
	at se.sics.nat.NatSetup.access$1000(NatSetup.java:74)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:202)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:188)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[11:13:00,746] INFO  {NatSetup} binding on nat:193.10.67.178:30000<1>OP
[11:13:00,746] TRACE {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> JOIN
[11:13:00,748] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[11:13:00,748] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: se.sics.nat.NatTraverserComp@36cc5582 has no negative se.sics.kompics.network.Network thrown in Component(ce49db7d-d6a0-4cc4-a876-6340f2a905cc):se.sics.nattest.NatTestLauncher@170ad4d5 while handling event se.sics.nat.stun.NatReady@20566350) 


[11:13:00,748] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:13:00,750] INFO  {Kompics} User declared that Fault KompicsFault(java.lang.RuntimeException: se.sics.nat.NatTraverserComp@36cc5582 has no negative se.sics.kompics.network.Network thrown in Component(ce49db7d-d6a0-4cc4-a876-6340f2a905cc):se.sics.nattest.NatTestLauncher@170ad4d5 while handling event se.sics.nat.stun.NatReady@20566350) should quit JVM...
[11:16:20,844] INFO  {NatTestLauncher} initiating
[11:16:21,094] INFO  {NatTestLauncher} starting
[11:16:21,183] INFO  {Config} System: seed:-4636197391102219564
[11:16:21,184] INFO  {Config} System: self ip:null port:30000 id:1
[11:16:21,186] INFO  {Config} System: caracal:missing
[11:16:21,186] INFO  {Config} System: aggregator:missing
[11:16:21,189] INFO  {Config} Nat:globalCroupier:0
[11:16:21,194] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:16:21,200] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:16:21,201] INFO  {Config} Nat:croupier bootstrap:[]
[11:16:21,205] INFO  {IpSolverComp} initiating...
[11:16:21,206] INFO  {IpSolverComp} starting...
[11:16:21,207] DEBUG {IpSolverComp} GetIp request
[11:16:21,215] DEBUG {IpSolverComp} GetIp responding
[11:16:21,215] INFO  {NatSetup} received local interfaces:[NI:name:en0 (en0) addr:/193.10.67.178 up:true mtu:1500 netPrefixLength:22, NI:name:lo0 (lo0) addr:/127.0.0.1 up:true mtu:16384 netPrefixLength:8]
[11:16:21,215] INFO  {NatSetup} multiple ips detected, proceeding with:/193.10.67.178
[11:16:21,216] INFO  {NatSetup} starting with local interface:/193.10.67.178
[11:16:21,217] INFO  {Config} Nat:globalCroupier:0
[11:16:21,217] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:16:21,218] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:16:21,219] INFO  {Config} Nat:croupier bootstrap:[]
[11:16:21,228] INFO  {NatDetectionComp} 193.10.67.178:30000<1> initiating...
[11:16:21,230] INFO  {NatDetectionComp} 193.10.67.178:30000<1> starting...
[11:16:21,234] INFO  {StunClientComp} /193.10.67.178<43211,43210> initiating...
[11:16:21,241] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting...
[11:16:21,241] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[11:16:21,242] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[11:16:21,244] INFO  {UpnpComp} nat upnp initiating...
[11:16:21,247] INFO  {UpnpComp} nat upnp starting...
[11:16:21,285] DEBUG {UpnpComp} nat upnp :Device notified:M-SEARCH * HTTP/1.1
ST: upnp:rootdevice
MX: 3
MAN: "ssdp:discover"
HOST: 239.255.255.250:1900


[11:16:21,375] INFO  {SocketUDT} library location : ./lib/bin
[11:16:21,375] INFO  {SocketUDT} loader provider  : com.barchart.udt.lib.LibraryLoaderUDT
[11:16:21,376] INFO  {PluginPropsUDT} ARCH/OS/LINK = x86_64/MacOSX/gpp
[11:16:21,378] INFO  {LibraryLoaderUDT} Platform supported.
[11:16:21,378] INFO  {LibraryLoaderUDT} Loading release libraries.
[11:16:21,489] INFO  {LibraryLoaderUDT} Release libraries loaded.
[11:16:21,503] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[11:16:21,504] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[11:16:21,519] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting new echo session:95869efc-9814-415a-822e-cefc647e2068
[11:16:21,519] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server1:193.10.64.107:54321<-1> 193.10.64.107:54320<-1>
[11:16:21,519] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server2:193.10.64.85:54321<-2> 193.10.64.85:54320<-2>
[11:16:21,520] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:SIP_SP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[11:16:21,612] INFO  {NettyNetwork@43211} Successfully bound to ip:port /193.10.67.178:43211
[11:16:21,612] INFO  {NettyNetwork@43210} Successfully bound to ip:port /193.10.67.178:43210
[11:16:21,629] INFO  {NettyNetwork@43211} Successfully bound UDT to ip:port /193.10.67.178:49605 with config: {CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, MAX_MESSAGES_PER_READ=16, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@4ca9b3b3, AUTO_READ=true, WRITE_SPIN_COUNT=16, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, WRITE_BUFFER_HIGH_WATER_MARK=65536, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@3ede2190, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, SO_SNDBUF=131072, SO_REUSEADDR=true, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), SO_RCVBUF=131072, SO_BACKLOG=64}
[11:16:21,629] INFO  {NettyNetwork@43210} Successfully bound UDT to ip:port /193.10.67.178:64978 with config: {CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, MAX_MESSAGES_PER_READ=16, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@4ca9b3b3, AUTO_READ=true, WRITE_SPIN_COUNT=16, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, WRITE_BUFFER_HIGH_WATER_MARK=65536, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@3ede2190, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, SO_SNDBUF=131072, SO_REUSEADDR=true, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), SO_RCVBUF=131072, SO_BACKLOG=64}
[11:16:21,643] INFO  {NettyNetwork@43211} Successfully bound to ip:port /193.10.67.178:43211
[11:16:21,643] TRACE {NettyNetwork@43211} Channel connected: UDP /193.10.67.178:43211 => null ([id: 0xb5e2d3fd, /193.10.67.178:43211])
[11:16:21,643] TRACE {NettyNetwork@43210} Channel connected: UDP /193.10.67.178:43210 => null ([id: 0x4574d15c, /193.10.67.178:43210])
[11:16:21,643] INFO  {NettyNetwork@43210} Successfully bound to ip:port /193.10.67.178:43210
[11:16:21,673] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicContentMsg, found: 133
[11:16:21,675] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:16:21,676] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@478ae7c5 for object STUN_ECHO_REQ<SIP_SP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:16:21,676] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedHeader, found: 132
[11:16:21,676] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:16:21,676] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@11c8cace for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@f8679503 (sID : [-124]) .
[11:16:21,676] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicHeader, found: 130
[11:16:21,676] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedAddress, found: 129
[11:16:21,677] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicAddress, found: 128
[11:16:21,682] TRACE {Serializers} Checked rule for class se.sics.nat.stun.msg.StunEcho$Request, found: 135
[11:16:21,682] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:16:21,682] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@6ecf70d1 for object STUN_ECHO_REQ<SIP_SP> (sID : [-121]) .
[11:16:21,683] TRACE {Serializers} Checked rule for class java.util.UUID, found: 6
[11:16:21,683] DEBUG {NettyNetwork@43211} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@55048c7d (61bytes)
[11:16:21,710] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:16:21,711] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@478ae7c5 for buffer with hint {}.
[11:16:21,711] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:16:21,711] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@11c8cace for buffer with hint {}.
[11:16:21,711] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:16:21,711] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@3be44e14 for buffer with hint Optional.absent().
[11:16:21,712] DEBUG {NettyNetwork@43211} Delivering message STUN_ECHO_RESP<SIP_SP>from:193.10.64.107:54321<-1>to:193.10.67.178:43211<1> from 193.10.64.107:54321<-1> to 193.10.67.178:43211<1> protocol UDP
[11:16:21,713] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<SIP_SP> from:193.10.64.107:54321<-1>
[11:16:21,713] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:DIP_DP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[11:16:21,722] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:16:21,722] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@478ae7c5 for object STUN_ECHO_REQ<DIP_DP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:16:21,722] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:16:21,722] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@11c8cace for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@f8679503 (sID : [-124]) .
[11:16:21,722] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:16:21,722] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@6ecf70d1 for object STUN_ECHO_REQ<DIP_DP> (sID : [-121]) .
[11:16:21,722] DEBUG {NettyNetwork@43211} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@54e6aac8 (72bytes)
[11:16:21,748] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:16:21,748] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@478ae7c5 for buffer with hint {}.
[11:16:21,748] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:16:21,748] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@11c8cace for buffer with hint {}.
[11:16:21,748] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:16:21,748] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@3be44e14 for buffer with hint Optional.absent().
[11:16:21,749] DEBUG {NettyNetwork@43211} Delivering message STUN_ECHO_RESP<DIP_DP>from:193.10.64.85:54320<-2>to:193.10.67.178:43211<1> from 193.10.64.85:54320<-2> to 193.10.67.178:43211<1> protocol UDP
[11:16:21,749] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<DIP_DP> from:193.10.64.85:54320<-2>
[11:16:21,757] INFO  {StunClientComp} /193.10.67.178<43211,43210> session result:OPEN
[11:16:21,759] INFO  {NatDetectionComp} 193.10.67.178:30000<1> nat detected:OP public ip:/193.10.67.178
[11:16:22,489] TRACE {Cybergarage} UP&P.getAddress() is called \o/
[11:16:22,489] DEBUG {Cybergarage} No UP&P device found, detection of the external ip address using the plugin has failed
[11:16:22,491] INFO  {NatDetectionComp} 193.10.67.178:30000<1> upnp ready:Optional.absent()
[11:16:22,491] INFO  {NatSetup} nat detected:OP public ip:/193.10.67.178 private ip:/193.10.67.178
[11:16:22,491] DEBUG {NatSetup} Initiating the binding on the socket to keep the port being used by some other service.
[11:16:22,492] DEBUG {NatSetup} Trying to bind on the socket1 with ip: /193.10.67.178 and port: 30000
[11:16:22,492] DEBUG {NatSetup} Socket successfully bound to ip :/193.10.67.178 and port: 30000
[11:16:22,493] DEBUG {NatSetup} {}Building the system configuration.
[11:16:22,495] INFO  {Config} Nat:globalCroupier:0
[11:16:22,495] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:16:22,495] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:16:22,495] INFO  {Config} Nat:croupier bootstrap:[]
[11:16:22,498] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:16:22,505] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[11:16:22,521] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:16:22,528] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[11:16:22,529] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[11:16:22,529] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[11:16:22,530] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting...
[11:16:22,530] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[11:16:22,531] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[11:16:22,531] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@27ba6d81
[11:16:22,531] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:16:22,531] INFO  {NatSetup} binding on nat:193.10.67.178:30000<1>OP
[11:16:22,531] TRACE {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> JOIN
[11:16:22,531] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[11:16:22,531] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:16:22,534] INFO  {ChunkManagerComp} config - datagramUsableSize:1000 cleanupTimeout:10000
[11:16:22,535] INFO  {NettyNetwork@30000} Successfully bound to ip:port /193.10.67.178:30000
[11:16:22,538] INFO  {NettyNetwork@30000} Successfully bound UDT to ip:port /193.10.67.178:51809 with config: {CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, MAX_MESSAGES_PER_READ=16, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@4ca9b3b3, AUTO_READ=true, WRITE_SPIN_COUNT=16, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, WRITE_BUFFER_HIGH_WATER_MARK=65536, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@3ede2190, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, SO_SNDBUF=131072, SO_REUSEADDR=true, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), SO_RCVBUF=131072, SO_BACKLOG=64}
[11:16:22,540] INFO  {NettyNetwork@30000} Successfully bound to ip:port /193.10.67.178:30000
[11:16:22,540] TRACE {NettyNetwork@30000} Channel connected: UDP /193.10.67.178:30000 => null ([id: 0x6da99997, /193.10.67.178:30000])
[11:16:22,540] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP initiating...
[11:16:22,540] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP starting...
[11:16:22,545] INFO  {PMServerComp} 193.10.67.178:30000<1> initiating...
[11:16:22,545] INFO  {PMServerComp} 193.10.67.178:30000<1> starting...
[11:16:22,552] INFO  {SHPClientComp} 193.10.67.178:30000<1> initiating...
[11:16:22,553] INFO  {SHPClientComp} 193.10.67.178:30000<1> starting...
[11:16:22,556] INFO  {HPServerComp} 193.10.67.178:30000<1> initiating...
[11:16:22,557] INFO  {HPServerComp} 193.10.67.178:30000<1> starting...
[11:16:27,549] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[11:16:32,552] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[11:16:32,552] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[11:16:32,558] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[11:16:37,549] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[11:16:42,548] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[11:16:42,549] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[11:16:42,559] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[11:16:42,559] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[11:16:47,550] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[11:16:52,550] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[11:16:52,550] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[11:16:52,551] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[11:16:52,554] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[11:16:52,558] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[11:16:52,558] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[11:16:52,559] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[11:16:52,559] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[11:18:12,361] INFO  {NatTestLauncher} initiating
[11:18:12,569] INFO  {NatTestLauncher} starting
[11:18:12,650] INFO  {Config} System: seed:-2131394927265683342
[11:18:12,650] INFO  {Config} System: self ip:null port:30000 id:1
[11:18:12,651] INFO  {Config} System: caracal:missing
[11:18:12,651] INFO  {Config} System: aggregator:missing
[11:18:12,655] INFO  {Config} Nat:globalCroupier:0
[11:18:12,660] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:18:12,664] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:18:12,665] INFO  {Config} Nat:croupier bootstrap:[]
[11:18:12,669] INFO  {IpSolverComp} initiating...
[11:18:12,671] INFO  {IpSolverComp} starting...
[11:18:12,672] DEBUG {IpSolverComp} GetIp request
[11:18:12,680] DEBUG {IpSolverComp} GetIp responding
[11:18:12,681] INFO  {Config} Nat:globalCroupier:0
[11:18:12,681] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:18:12,682] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:18:12,682] INFO  {Config} Nat:croupier bootstrap:[]
[11:18:12,998] INFO  {NettyNetwork@43210} Successfully bound to ip:port /193.10.67.178:43210
[11:18:12,998] INFO  {NettyNetwork@43211} Successfully bound to ip:port /193.10.67.178:43211
[11:18:13,016] INFO  {NettyNetwork@43211} Successfully bound UDT to ip:port /193.10.67.178:63338 with config: {RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@30ae3373, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, SO_BACKLOG=64, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, SO_SNDBUF=131072, AUTO_READ=true, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, SO_REUSEADDR=true, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@1271bc74, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, MAX_MESSAGES_PER_READ=16, WRITE_BUFFER_HIGH_WATER_MARK=65536, WRITE_SPIN_COUNT=16, SO_RCVBUF=131072, CONNECT_TIMEOUT_MILLIS=30000}
[11:18:13,016] INFO  {NettyNetwork@43210} Successfully bound UDT to ip:port /193.10.67.178:59314 with config: {RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@30ae3373, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, SO_BACKLOG=64, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, SO_SNDBUF=131072, AUTO_READ=true, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, SO_REUSEADDR=true, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@1271bc74, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, MAX_MESSAGES_PER_READ=16, WRITE_BUFFER_HIGH_WATER_MARK=65536, WRITE_SPIN_COUNT=16, SO_RCVBUF=131072, CONNECT_TIMEOUT_MILLIS=30000}
[11:18:13,032] INFO  {NettyNetwork@43211} Successfully bound to ip:port /193.10.67.178:43211
[11:18:13,032] TRACE {NettyNetwork@43211} Channel connected: UDP /193.10.67.178:43211 => null ([id: 0x12277ac2, /193.10.67.178:43211])
[11:18:13,033] TRACE {NettyNetwork@43210} Channel connected: UDP /193.10.67.178:43210 => null ([id: 0x4520844e, /193.10.67.178:43210])
[11:18:13,032] INFO  {NettyNetwork@43210} Successfully bound to ip:port /193.10.67.178:43210
[11:18:13,064] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicContentMsg, found: 133
[11:18:13,066] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:18:13,066] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@5c071207 for object STUN_ECHO_REQ<SIP_SP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:18:13,066] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedHeader, found: 132
[11:18:13,066] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:18:13,067] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@1fb003bd for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@cb5c03b8 (sID : [-124]) .
[11:18:13,067] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicHeader, found: 130
[11:18:13,067] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedAddress, found: 129
[11:18:13,067] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicAddress, found: 128
[11:18:13,072] TRACE {Serializers} Checked rule for class se.sics.nat.stun.msg.StunEcho$Request, found: 135
[11:18:13,072] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:18:13,073] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@54da1e9c for object STUN_ECHO_REQ<SIP_SP> (sID : [-121]) .
[11:18:13,073] TRACE {Serializers} Checked rule for class java.util.UUID, found: 6
[11:18:13,074] DEBUG {NettyNetwork@43211} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@1d7fcc74 (61bytes)
[11:18:13,111] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:18:13,112] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@5c071207 for buffer with hint {}.
[11:18:13,112] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:18:13,112] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@1fb003bd for buffer with hint {}.
[11:18:13,112] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:18:13,112] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@1839c2b6 for buffer with hint Optional.absent().
[11:18:13,113] DEBUG {NettyNetwork@43211} Delivering message STUN_ECHO_RESP<SIP_SP>from:193.10.64.107:54321<-1>to:193.10.67.178:43211<1> from 193.10.64.107:54321<-1> to 193.10.67.178:43211<1> protocol UDP
[11:18:13,130] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:18:13,131] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@5c071207 for object STUN_ECHO_REQ<DIP_DP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:18:13,131] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:18:13,131] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@1fb003bd for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@cb5c03b8 (sID : [-124]) .
[11:18:13,131] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:18:13,131] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@54da1e9c for object STUN_ECHO_REQ<DIP_DP> (sID : [-121]) .
[11:18:13,131] DEBUG {NettyNetwork@43211} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@c6f9c32 (72bytes)
[11:18:13,185] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:18:13,186] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@5c071207 for buffer with hint {}.
[11:18:13,187] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:18:13,188] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@1fb003bd for buffer with hint {}.
[11:18:13,189] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:18:13,189] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@1839c2b6 for buffer with hint Optional.absent().
[11:18:13,189] DEBUG {NettyNetwork@43211} Delivering message STUN_ECHO_RESP<DIP_DP>from:193.10.64.85:54320<-2>to:193.10.67.178:43211<1> from 193.10.64.85:54320<-2> to 193.10.67.178:43211<1> protocol UDP
[11:18:13,952] INFO  {Config} Nat:globalCroupier:0
[11:18:13,953] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:18:13,954] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:18:13,954] INFO  {Config} Nat:croupier bootstrap:[]
[11:18:13,958] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:18:13,986] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:18:13,995] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[11:18:13,996] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[11:18:13,996] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[11:18:13,998] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[11:18:13,998] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@4906f29
[11:18:13,998] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:18:13,998] TRACE {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> JOIN
[11:18:13,998] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[11:18:13,998] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:18:14,001] INFO  {ChunkManagerComp} config - datagramUsableSize:1000 cleanupTimeout:10000
[11:18:14,002] INFO  {NettyNetwork@30000} Successfully bound to ip:port /193.10.67.178:30000
[11:18:14,009] INFO  {NettyNetwork@30000} Successfully bound UDT to ip:port /193.10.67.178:65297 with config: {RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@30ae3373, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, SO_BACKLOG=64, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, SO_SNDBUF=131072, AUTO_READ=true, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, SO_REUSEADDR=true, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@1271bc74, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, MAX_MESSAGES_PER_READ=16, WRITE_BUFFER_HIGH_WATER_MARK=65536, WRITE_SPIN_COUNT=16, SO_RCVBUF=131072, CONNECT_TIMEOUT_MILLIS=30000}
[11:18:14,011] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP initiating...
[11:18:14,011] TRACE {NettyNetwork@30000} Channel connected: UDP /193.10.67.178:30000 => null ([id: 0x04b98f38, /193.10.67.178:30000])
[11:18:14,011] INFO  {NettyNetwork@30000} Successfully bound to ip:port /193.10.67.178:30000
[11:18:14,011] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP starting...
[11:19:29,874] INFO  {NatTestLauncher} initiating
[11:19:30,084] INFO  {NatTestLauncher} starting
[11:19:30,168] INFO  {Config} System: seed:2754661436111733040
[11:19:30,168] INFO  {Config} System: self ip:null port:30000 id:1
[11:19:30,170] INFO  {Config} System: caracal:missing
[11:19:30,171] INFO  {Config} System: aggregator:missing
[11:19:30,174] INFO  {Config} Nat:globalCroupier:0
[11:19:30,178] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:19:30,183] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:19:30,183] INFO  {Config} Nat:croupier bootstrap:[]
[11:19:30,187] INFO  {IpSolverComp} initiating...
[11:19:30,188] INFO  {IpSolverComp} starting...
[11:19:30,189] DEBUG {IpSolverComp} GetIp request
[11:19:30,195] DEBUG {IpSolverComp} GetIp responding
[11:19:30,196] INFO  {Config} Nat:globalCroupier:0
[11:19:30,196] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:19:30,197] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:19:30,197] INFO  {Config} Nat:croupier bootstrap:[]
[11:19:30,565] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicContentMsg, found: 133
[11:19:30,566] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:19:30,566] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@d629779 for object STUN_ECHO_REQ<SIP_SP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:19:30,567] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedHeader, found: 132
[11:19:30,567] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:19:30,567] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@277a75de for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@bbe0f9f5 (sID : [-124]) .
[11:19:30,567] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicHeader, found: 130
[11:19:30,572] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.DecoratedAddress, found: 129
[11:19:30,572] TRACE {Serializers} Checked rule for class se.sics.p2ptoolbox.util.network.impl.BasicAddress, found: 128
[11:19:30,576] TRACE {Serializers} Checked rule for class se.sics.nat.stun.msg.StunEcho$Request, found: 135
[11:19:30,576] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:19:30,577] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@66c3601f for object STUN_ECHO_REQ<SIP_SP> (sID : [-121]) .
[11:19:30,577] TRACE {Serializers} Checked rule for class java.util.UUID, found: 6
[11:19:30,610] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:19:30,610] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@d629779 for buffer with hint {}.
[11:19:30,610] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:19:30,610] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@277a75de for buffer with hint {}.
[11:19:30,611] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:19:30,611] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@3be44e14 for buffer with hint Optional.absent().
[11:19:30,628] TRACE {Serializers} ID: [0, 0, 0, -123] (3, 4)
[11:19:30,628] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@d629779 for object STUN_ECHO_REQ<DIP_DP>from:193.10.67.178:43211<1>to:193.10.64.107:54321<-1> (sID : [-123]) .
[11:19:30,628] TRACE {Serializers} ID: [0, 0, 0, -124] (3, 4)
[11:19:30,628] DEBUG {Serializers} Using serializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@277a75de for object se.sics.p2ptoolbox.util.network.impl.DecoratedHeader@bbe0f9f5 (sID : [-124]) .
[11:19:30,629] TRACE {Serializers} ID: [0, 0, 0, -121] (3, 4)
[11:19:30,629] DEBUG {Serializers} Using serializer se.sics.nat.stun.msg.StunEchoSerializer$Request@66c3601f for object STUN_ECHO_REQ<DIP_DP> (sID : [-121]) .
[11:19:30,638] TRACE {Serializers} DS-ID: 133 ([-123], 4)
[11:19:30,638] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.BasicContentMsgSerializer@d629779 for buffer with hint {}.
[11:19:30,638] TRACE {Serializers} DS-ID: 132 ([-124], 4)
[11:19:30,639] DEBUG {Serializers} Using deserializer se.sics.p2ptoolbox.util.network.impl.DecoratedHeaderSerializer@277a75de for buffer with hint {}.
[11:19:30,639] TRACE {Serializers} DS-ID: 136 ([-120], 4)
[11:19:30,639] DEBUG {Serializers} Using deserializer se.sics.nat.stun.msg.StunEchoSerializer$Response@3be44e14 for buffer with hint Optional.absent().
[11:19:31,470] INFO  {Config} Nat:globalCroupier:0
[11:19:31,471] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:19:31,471] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:19:31,472] INFO  {Config} Nat:croupier bootstrap:[]
[11:19:31,475] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:19:31,499] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:19:31,507] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[11:19:31,509] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[11:19:31,510] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[11:19:31,512] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[11:19:31,512] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@275c6da4
[11:19:31,512] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:19:31,512] TRACE {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> JOIN
[11:19:31,512] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[11:19:31,512] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:19:31,516] INFO  {ChunkManagerComp} config - datagramUsableSize:1000 cleanupTimeout:10000
[11:19:31,525] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP initiating...
[11:19:31,526] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP starting...
[11:20:15,823] INFO  {NatTestLauncher} initiating
[11:20:16,012] INFO  {NatTestLauncher} starting
[11:20:16,096] INFO  {Config} System: seed:5622668589923807274
[11:20:16,097] INFO  {Config} System: self ip:null port:30000 id:1
[11:20:16,097] INFO  {Config} System: caracal:missing
[11:20:16,098] INFO  {Config} System: aggregator:missing
[11:20:16,099] INFO  {Config} Nat:globalCroupier:0
[11:20:16,102] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:20:16,107] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:20:16,107] INFO  {Config} Nat:croupier bootstrap:[]
[11:20:16,110] INFO  {IpSolverComp} initiating...
[11:20:16,110] INFO  {IpSolverComp} starting...
[11:20:16,111] DEBUG {IpSolverComp} GetIp request
[11:20:16,117] DEBUG {IpSolverComp} GetIp responding
[11:20:16,119] INFO  {Config} Nat:globalCroupier:0
[11:20:16,119] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:20:16,120] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:20:16,120] INFO  {Config} Nat:croupier bootstrap:[]
[11:20:17,383] INFO  {Config} Nat:globalCroupier:0
[11:20:17,383] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:20:17,385] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:20:17,385] INFO  {Config} Nat:croupier bootstrap:[]
[11:20:17,388] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:20:17,414] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[11:20:17,420] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[11:20:17,421] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[11:20:17,423] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[11:20:17,427] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[11:20:17,427] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@1d191157
[11:20:17,427] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:20:17,428] TRACE {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> JOIN
[11:20:17,428] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[11:20:17,428] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[11:20:17,433] INFO  {ChunkManagerComp} config - datagramUsableSize:1000 cleanupTimeout:10000
[11:20:17,446] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP initiating...
[11:20:17,447] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP starting...
[11:21:19,392] INFO  {NatTestLauncher} initiating
[11:21:19,592] INFO  {NatTestLauncher} starting
[11:21:19,664] INFO  {Config} System: seed:7283750789817729595
[11:21:19,664] INFO  {Config} System: self ip:null port:30000 id:1
[11:21:19,665] INFO  {Config} System: caracal:missing
[11:21:19,665] INFO  {Config} System: aggregator:missing
[11:21:19,667] INFO  {Config} Nat:globalCroupier:0
[11:21:19,671] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:21:19,676] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:21:19,676] INFO  {Config} Nat:croupier bootstrap:[]
[11:21:19,679] INFO  {IpSolverComp} initiating...
[11:21:19,680] INFO  {IpSolverComp} starting...
[11:21:19,681] DEBUG {IpSolverComp} GetIp request
[11:21:19,693] DEBUG {IpSolverComp} GetIp responding
[11:21:19,695] INFO  {Config} Nat:globalCroupier:0
[11:21:19,695] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:21:19,696] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:21:19,696] INFO  {Config} Nat:croupier bootstrap:[]
[11:21:20,960] INFO  {Config} Nat:globalCroupier:0
[11:21:20,960] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:21:20,962] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:21:20,962] INFO  {Config} Nat:croupier bootstrap:[]
[11:21:21,003] INFO  {ChunkManagerComp} config - datagramUsableSize:1000 cleanupTimeout:10000
[11:21:21,011] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP initiating...
[11:21:21,011] INFO  {ChunkManagerComp} 193.10.67.178:30000<1>OP starting...
[11:21:50,851] INFO  {NatTestLauncher} initiating
[11:21:51,053] INFO  {NatTestLauncher} starting
[11:21:51,128] INFO  {Config} System: seed:-2502454583983645687
[11:21:51,129] INFO  {Config} System: self ip:null port:30000 id:1
[11:21:51,130] INFO  {Config} System: caracal:missing
[11:21:51,131] INFO  {Config} System: aggregator:missing
[11:21:51,133] INFO  {Config} Nat:globalCroupier:0
[11:21:51,136] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:21:51,144] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:21:51,144] INFO  {Config} Nat:croupier bootstrap:[]
[11:21:51,147] INFO  {IpSolverComp} initiating...
[11:21:51,148] INFO  {IpSolverComp} starting...
[11:21:51,149] DEBUG {IpSolverComp} GetIp request
[11:21:51,155] DEBUG {IpSolverComp} GetIp responding
[11:21:51,159] INFO  {Config} Nat:globalCroupier:0
[11:21:51,159] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:21:51,161] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:21:51,162] INFO  {Config} Nat:croupier bootstrap:[]
[11:21:52,436] INFO  {Config} Nat:globalCroupier:0
[11:21:52,437] INFO  {Config} Nat:stun client port1:43211 port2:43210
[11:21:52,444] INFO  {Config} Nat:stun servers:[[193.10.64.107:54321<-1>, 193.10.64.107:54320<-1>], [193.10.64.85:54321<-2>, 193.10.64.85:54320<-2>]]
[11:21:52,445] INFO  {Config} Nat:croupier bootstrap:[]
[11:22:59,244] INFO  {NatTestLauncher} initiating
[11:22:59,471] INFO  {NatTestLauncher} starting
[15:02:02,883] INFO  {NatTestLauncher} initiating
[15:02:03,105] INFO  {NatTestLauncher} starting
[15:02:03,225] INFO  {NatTestLauncher} waiting for nat
[15:02:04,567] INFO  {NatTestLauncher} nat started
[15:02:04,570] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.NullPointerException
	at se.sics.nattest.NatTestComp.<init>(NatTestComp.java:68)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at java.lang.Class.newInstance(Class.java:433)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:231)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:195)
	at se.sics.nattest.NatTestLauncher.connectNStartApp(NatTestLauncher.java:122)
	at se.sics.nattest.NatTestLauncher.access$700(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.startApp(NatTestLauncher.java:137)
	at se.sics.nat.NatSetup.finish(NatSetup.java:281)
	at se.sics.nat.NatSetup.access$1000(NatSetup.java:74)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:202)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:188)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:02:04,586] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.NullPointerException thrown in Component(75222ad2-ccdf-4072-92e0-2b84fb061839):se.sics.nattest.NatTestLauncher@20bc77 while handling event se.sics.nat.stun.NatReady@57a8c7a4) 


[15:02:49,511] INFO  {NatTestLauncher} initiating
[15:02:49,717] INFO  {NatTestLauncher} starting
[15:02:49,816] INFO  {NatTestLauncher} waiting for nat
[15:02:51,136] INFO  {NatTestLauncher} nat started
[15:02:51,140] INFO  {NatTestComp} initiating
[15:02:51,140] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: se.sics.nattest.NatTestComp@6c38b754 has no positive se.sics.kompics.network.Network
	at se.sics.kompics.JavaComponent.getPositive(JavaComponent.java:116)
	at se.sics.nattest.NatTestLauncher.connectNStartApp(NatTestLauncher.java:123)
	at se.sics.nattest.NatTestLauncher.access$700(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.startApp(NatTestLauncher.java:137)
	at se.sics.nat.NatSetup.finish(NatSetup.java:281)
	at se.sics.nat.NatSetup.access$1000(NatSetup.java:74)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:202)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:188)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:02:51,147] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: se.sics.nattest.NatTestComp@6c38b754 has no positive se.sics.kompics.network.Network thrown in Component(64837573-fbad-49dd-8ec6-ae36ca7c47f6):se.sics.nattest.NatTestLauncher@540dc29e while handling event se.sics.nat.stun.NatReady@5a60a46f) 


[15:28:01,907] INFO  {NatTestLauncher} initiating
[15:28:02,150] INFO  {NatTestLauncher} starting
[15:28:02,236] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:222)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:182)
	at se.sics.nattest.NatTestLauncher.access$1100(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.create(NatTestLauncher.java:157)
	at se.sics.nat.NatSetup.setupPhase1(NatSetup.java:108)
	at se.sics.nat.NatSetup.start(NatSetup.java:103)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:118)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:104)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:99)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:236)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 17 more
Caused by: java.lang.NullPointerException
	at se.sics.ktoolbox.ipsolver.IpSolverComp.<init>(IpSolverComp.java:57)
	... 23 more
[15:28:02,239] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp thrown in Component(0b874a93-a662-457c-a871-1fc48492ca05):se.sics.nattest.NatTestLauncher@4d7c498f while handling event se.sics.kompics.Start@6065d6fc) 


[15:30:56,570] INFO  {NatTestLauncher} initiating
[15:30:56,813] INFO  {NatTestLauncher} starting
[15:30:56,930] ERROR {IpSolverComp} java.net.preferIPv4Stack not set
[15:30:56,930] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:222)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:182)
	at se.sics.nattest.NatTestLauncher.access$1100(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.create(NatTestLauncher.java:157)
	at se.sics.nat.NatSetup.setupPhase1(NatSetup.java:108)
	at se.sics.nat.NatSetup.start(NatSetup.java:103)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:118)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:104)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:99)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:236)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 17 more
Caused by: java.lang.RuntimeException: java.net.preferIPv4Stack not set
	at se.sics.ktoolbox.ipsolver.IpSolverComp.<init>(IpSolverComp.java:60)
	... 23 more
[15:30:56,933] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp thrown in Component(b9c6049f-121c-4720-beb7-50950f11c227):se.sics.nattest.NatTestLauncher@51dc7c4e while handling event se.sics.kompics.Start@12a3838e) 


[15:32:12,275] INFO  {NatTestLauncher} initiating
[15:32:12,440] INFO  {NatTestLauncher} starting
[15:32:12,528] ERROR {IpSolverComp} java.net.preferIPv4Stack not set
[15:32:12,528] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:222)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:182)
	at se.sics.nattest.NatTestLauncher.access$1100(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.create(NatTestLauncher.java:157)
	at se.sics.nat.NatSetup.setupPhase1(NatSetup.java:108)
	at se.sics.nat.NatSetup.start(NatSetup.java:103)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:118)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:104)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:99)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:236)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 17 more
Caused by: java.lang.RuntimeException: java.net.preferIPv4Stack not set
	at se.sics.ktoolbox.ipsolver.IpSolverComp.<init>(IpSolverComp.java:60)
	... 23 more
[15:32:12,531] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp thrown in Component(aac685e4-de2d-4518-8d60-c22a1dd1daee):se.sics.nattest.NatTestLauncher@c81229b while handling event se.sics.kompics.Start@583cf007) 


[15:34:03,305] INFO  {NatTestLauncher} initiating
[15:34:03,510] INFO  {NatTestLauncher} starting
[15:34:03,612] ERROR {IpSolverComp} java.net.preferIPv4Stack not set
[15:34:03,612] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:222)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:182)
	at se.sics.nattest.NatTestLauncher.access$1100(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.create(NatTestLauncher.java:157)
	at se.sics.nat.NatSetup.setupPhase1(NatSetup.java:108)
	at se.sics.nat.NatSetup.start(NatSetup.java:103)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:118)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:104)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:99)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:236)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 17 more
Caused by: java.lang.RuntimeException: java.net.preferIPv4Stack not set
	at se.sics.ktoolbox.ipsolver.IpSolverComp.<init>(IpSolverComp.java:60)
	... 23 more
[15:34:03,616] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp thrown in Component(cf02b4b7-88d9-421d-ae3f-eb05c399d755):se.sics.nattest.NatTestLauncher@50905f40 while handling event se.sics.kompics.Start@7c2a8054) 


[15:34:28,856] INFO  {NatTestLauncher} initiating
[15:34:29,052] INFO  {NatTestLauncher} starting
[15:34:29,141] ERROR {IpSolverComp} java.net.preferIPv4Stack not set
[15:34:29,142] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:222)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:182)
	at se.sics.nattest.NatTestLauncher.access$1100(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.create(NatTestLauncher.java:162)
	at se.sics.nat.NatSetup.setupPhase1(NatSetup.java:108)
	at se.sics.nat.NatSetup.start(NatSetup.java:103)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:123)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:109)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:104)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:236)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 17 more
Caused by: java.lang.RuntimeException: java.net.preferIPv4Stack not set
	at se.sics.ktoolbox.ipsolver.IpSolverComp.<init>(IpSolverComp.java:60)
	... 23 more
[15:34:29,148] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp thrown in Component(74576be6-eafb-40f6-bbc0-3e201dcb5f47):se.sics.nattest.NatTestLauncher@520508af while handling event se.sics.kompics.Start@42f48c3d) 


[15:38:14,622] INFO  {NatTestLauncher} initiating
[15:38:14,857] INFO  {NatTestLauncher} starting
[15:38:14,953] INFO  {NatTestLauncher} waiting for nat
[15:38:16,240] INFO  {NatTestLauncher} nat started
[15:38:16,249] INFO  {NatTestComp} initiating
[15:38:16,250] INFO  {NatTestComp} starting
[15:41:37,569] INFO  {NatTestLauncher} initiating
[15:41:37,745] INFO  {NatTestLauncher} starting
[15:41:37,835] INFO  {NatTestLauncher} waiting for nat
[15:41:38,138] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:41:38,138] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:41:38,140] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:5b1ed1cc-2130-4578-887c-ef3168f26712 - restarting hook...
[15:41:38,145] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:d6701f34-9500-4beb-9924-03f06cfa9495 - restarting hook...
[15:41:38,148] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:41:38,149] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:6fa4c4e9-5d7f-4496-9e97-c9e4cbab6155 - restarting hook...
[15:41:38,152] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:41:38,153] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:2dbd5a31-6a6e-47f0-93a8-f233afcccee1 - restarting hook...
[15:41:38,154] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:41:38,155] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:c0776fd4-e40a-4bfb-899a-8287c54d2286 - restarting hook...
[15:41:38,155] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[15:41:38,155] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:41:38,156] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:4008676b-689b-4cbf-9ae3-14468cb25bbc
[15:41:38,156] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(4008676b-689b-4cbf-9ae3-14468cb25bbc):se.sics.nat.stun.client.StunClientComp@17f23c8d while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(c0776fd4-e40a-4bfb-899a-8287c54d2286):se.sics.kompics.network.netty.NettyNetwork@46b086aa while handling event se.sics.kompics.Start@8fd1f20)) 


[15:41:38,158] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:42:23,436] INFO  {NatTestLauncher} initiating
[15:42:23,652] INFO  {NatTestLauncher} starting
[15:42:23,767] INFO  {NatTestLauncher} waiting for nat
[15:42:25,119] INFO  {NatTestLauncher} nat started
[15:42:25,126] INFO  {NatTestComp} initiating
[15:42:25,126] INFO  {NatTestComp} starting
[15:42:25,126] INFO  {NatTestComp} waiting for self address
[15:47:36,229] INFO  {NatTestLauncher} initiating
[15:47:36,422] INFO  {NatTestLauncher} starting
[15:47:36,544] ERROR {IpSolverComp} java.net.preferIPv4Stack not set
[15:47:36,545] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:222)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:182)
	at se.sics.nattest.NatTestLauncher.access$1100(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.create(NatTestLauncher.java:157)
	at se.sics.nat.NatSetup.setupPhase1(NatSetup.java:108)
	at se.sics.nat.NatSetup.start(NatSetup.java:103)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:118)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:63)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:104)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:99)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:236)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 17 more
Caused by: java.lang.RuntimeException: java.net.preferIPv4Stack not set
	at se.sics.ktoolbox.ipsolver.IpSolverComp.<init>(IpSolverComp.java:59)
	... 23 more
[15:47:36,548] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.ktoolbox.ipsolver.IpSolverComp thrown in Component(0b180f25-8fb1-477e-8678-d84350a95ab0):se.sics.nattest.NatTestLauncher@1772ae1b while handling event se.sics.kompics.Start@525ec8e5) 


[15:48:58,967] INFO  {NatTestLauncher} initiating
[15:48:59,205] INFO  {NatTestLauncher} starting
[15:48:59,315] INFO  {NatTestLauncher} waiting for nat
[15:48:59,652] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:48:59,652] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:48:59,654] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:5531c58b-a121-428f-b322-1d5c5d338825 - restarting hook...
[15:48:59,658] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:248a7ee2-2761-496a-893a-765ab12150bf - restarting hook...
[15:48:59,661] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:48:59,661] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:9adbdd2c-dc1f-47e4-89fd-50d224d8cd4f - restarting hook...
[15:48:59,664] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:48:59,665] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:8cda168c-7456-46f1-ba6d-9bd5bce33a58 - restarting hook...
[15:48:59,667] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:48:59,668] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:9b3d6e35-4dc5-473a-b002-e8078799afd1 - restarting hook...
[15:48:59,668] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[15:48:59,668] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:48:59,669] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:dd4f706e-7adb-4c36-904f-c12ebbac1ac2
[15:48:59,669] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(dd4f706e-7adb-4c36-904f-c12ebbac1ac2):se.sics.nat.stun.client.StunClientComp@5ef2dd12 while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(9b3d6e35-4dc5-473a-b002-e8078799afd1):se.sics.kompics.network.netty.NettyNetwork@9d993b6 while handling event se.sics.kompics.Start@3c73e411)) 


[15:49:23,097] INFO  {NatTestLauncher} initiating
[15:49:23,337] INFO  {NatTestLauncher} starting
[15:49:23,458] INFO  {NatTestLauncher} waiting for nat
[15:49:24,758] INFO  {NatTestLauncher} nat started
[15:49:24,761] INFO  {NatTestComp} initiating
[15:49:24,762] INFO  {NatTestComp} starting
[15:49:24,763] INFO  {NatTestComp} waiting for self address
[15:51:01,087] INFO  {NatTestLauncher} initiating
[15:51:01,337] INFO  {NatTestLauncher} starting
[15:51:01,466] INFO  {NatTestLauncher} waiting for nat
[15:51:02,757] INFO  {NatTestLauncher} nat started
[15:51:02,759] INFO  {NatTestComp} initiating
[15:51:02,760] INFO  {NatTestComp} starting
[15:51:02,760] INFO  {NatTestComp} waiting for self address
[15:51:29,413] INFO  {NatTestLauncher} initiating
[15:51:29,581] INFO  {NatTestLauncher} starting
[15:51:29,668] INFO  {NatTestLauncher} waiting for nat
[15:51:29,957] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:51:29,957] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:51:29,959] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:cc906873-d843-4099-b1b4-c83fad5c80dc - restarting hook...
[15:51:29,962] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:ccbc127f-5232-4d3f-9361-65c4ea99a24c - restarting hook...
[15:51:29,965] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:51:29,966] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:ec1881e3-58b4-45db-ba03-1543d51f709e - restarting hook...
[15:51:29,967] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:51:29,968] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:f359418d-f6fe-4834-803f-a833eb615cc9 - restarting hook...
[15:51:29,972] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:51:29,973] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:27360636-82c7-40e9-9c6e-252d2bdcae84 - restarting hook...
[15:51:29,973] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[15:51:29,973] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:51:29,974] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:51:29,974] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:0b1cb1bf-38b4-4edb-b771-74f0c4b4b3f3
[15:51:29,975] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(0b1cb1bf-38b4-4edb-b771-74f0c4b4b3f3):se.sics.nat.stun.client.StunClientComp@303ea072 while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(27360636-82c7-40e9-9c6e-252d2bdcae84):se.sics.kompics.network.netty.NettyNetwork@17f9661f while handling event se.sics.kompics.Start@3b3d435)) 


[15:51:38,822] INFO  {NatTestLauncher} initiating
[15:51:39,041] INFO  {NatTestLauncher} starting
[15:51:39,132] INFO  {NatTestLauncher} waiting for nat
[15:51:40,426] INFO  {NatTestLauncher} nat started
[15:51:40,430] INFO  {NatTestComp} initiating
[15:51:40,431] INFO  {NatTestComp} starting
[15:51:40,432] INFO  {NatTestComp} waiting for self address
[15:52:18,207] INFO  {NatTestLauncher} initiating
[15:52:18,403] INFO  {NatTestLauncher} starting
[15:52:18,518] INFO  {NatTestLauncher} waiting for nat
[15:52:18,527] INFO  {NatSetup} received local interfaces:[NI:name:en0 (en0) addr:/193.10.67.178 up:true mtu:1500 netPrefixLength:22, NI:name:lo0 (lo0) addr:/127.0.0.1 up:true mtu:16384 netPrefixLength:8]
[15:52:18,528] INFO  {NatSetup} multiple ips detected, proceeding with:/193.10.67.178
[15:52:18,528] INFO  {NatSetup} starting with local interface:/193.10.67.178
[15:52:18,538] INFO  {NatDetectionComp} 193.10.67.178:30000<1> initiating...
[15:52:18,540] INFO  {NatDetectionComp} 193.10.67.178:30000<1> starting...
[15:52:18,543] INFO  {StunClientComp} /193.10.67.178<43211,43210> initiating...
[15:52:18,548] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting...
[15:52:18,548] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[15:52:18,548] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[15:52:18,550] INFO  {UpnpComp} nat upnp initiating...
[15:52:18,553] INFO  {UpnpComp} nat upnp starting...
[15:52:18,588] DEBUG {UpnpComp} nat upnp :Device notified:M-SEARCH * HTTP/1.1
ST: upnp:rootdevice
MX: 3
MAN: "ssdp:discover"
HOST: 239.255.255.250:1900


[15:52:18,759] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[15:52:18,760] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[15:52:18,766] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting new echo session:5837c540-0b75-467c-a39e-e714715408d3
[15:52:18,767] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server1:193.10.64.107:54321<-1> 193.10.64.107:54320<-1>
[15:52:18,767] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server2:193.10.64.85:54321<-2> 193.10.64.85:54320<-2>
[15:52:18,768] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:SIP_SP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[15:52:18,962] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<SIP_SP> from:193.10.64.107:54321<-1>
[15:52:18,963] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:DIP_DP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[15:52:18,986] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<DIP_DP> from:193.10.64.85:54320<-2>
[15:52:18,986] INFO  {StunClientComp} /193.10.67.178<43211,43210> session result:OPEN
[15:52:18,988] INFO  {NatDetectionComp} 193.10.67.178:30000<1> nat detected:OP public ip:/193.10.67.178
[15:52:19,787] TRACE {Cybergarage} UP&P.getAddress() is called \o/
[15:52:19,787] DEBUG {Cybergarage} No UP&P device found, detection of the external ip address using the plugin has failed
[15:52:19,791] INFO  {NatDetectionComp} 193.10.67.178:30000<1> upnp ready:Optional.absent()
[15:52:19,791] INFO  {NatSetup} nat detected:OP public ip:/193.10.67.178 private ip:/193.10.67.178
[15:52:19,791] DEBUG {NatSetup} Initiating the binding on the socket to keep the port being used by some other service.
[15:52:19,792] DEBUG {NatSetup} Trying to bind on the socket1 with ip: /193.10.67.178 and port: 30000
[15:52:19,792] DEBUG {NatSetup} Socket successfully bound to ip :/193.10.67.178 and port: 30000
[15:52:19,793] DEBUG {NatSetup} {}Building the system configuration.
[15:52:19,803] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[15:52:19,821] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting...
[15:52:19,821] INFO  {NatTestLauncher} nat started
[15:52:19,821] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[15:52:19,822] INFO  {NatSetup} binding on nat:193.10.67.178:30000<1>OP
[15:52:19,823] INFO  {NatTestComp} initiating
[15:52:19,823] INFO  {NatTestComp} starting
[15:52:19,824] INFO  {NatTestComp} waiting for self address
[15:52:19,833] INFO  {PMServerComp} 193.10.67.178:30000<1> initiating...
[15:52:19,834] INFO  {PMServerComp} 193.10.67.178:30000<1> starting...
[15:52:19,844] INFO  {SHPClientComp} 193.10.67.178:30000<1> initiating...
[15:52:19,844] INFO  {SHPClientComp} 193.10.67.178:30000<1> starting...
[15:52:19,848] INFO  {HPServerComp} 193.10.67.178:30000<1> initiating...
[15:52:19,850] INFO  {HPServerComp} 193.10.67.178:30000<1> starting...
[15:52:24,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:29,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:29,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:52:29,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:52:34,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:39,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:39,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:52:39,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:52:39,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:52:44,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:49,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:49,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:52:49,838] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:52:49,845] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:52:49,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:52:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:52:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:52:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:52:54,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:59,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:52:59,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:52:59,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:52:59,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:53:04,836] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:09,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:09,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:53:09,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:53:14,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:19,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:19,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:53:19,840] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:53:19,846] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:53:19,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:53:19,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:53:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:53:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:53:19,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:53:24,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:29,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:29,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:53:29,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:53:34,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:39,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:39,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:53:39,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:53:39,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:53:44,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:49,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:49,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:53:49,842] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:53:49,844] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:53:49,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:53:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:53:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:53:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:53:54,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:59,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:53:59,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:53:59,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:53:59,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:54:04,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:09,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:09,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:54:09,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:54:14,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:19,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:19,839] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:54:19,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:54:19,845] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:54:19,851] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:54:19,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:54:19,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:54:19,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:54:19,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:54:24,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:29,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:29,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:54:29,855] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:54:34,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:39,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:39,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:54:39,855] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:54:39,855] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:54:44,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:49,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:49,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:54:49,839] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:54:49,845] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:54:49,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:54:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:54:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:54:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:54:54,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:59,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:54:59,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:54:59,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:54:59,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:55:04,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:09,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:09,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:55:09,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:55:14,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:19,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:19,841] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:55:19,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:55:19,844] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:55:19,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:55:19,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:55:19,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:55:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:55:19,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:55:24,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:29,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:29,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:55:29,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:55:34,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:39,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:39,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:55:39,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:55:39,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:55:44,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:49,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:49,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:55:49,837] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:55:49,846] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:55:49,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:55:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:55:49,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:55:49,854] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:55:54,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:59,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:55:59,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:55:59,851] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:55:59,851] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:04,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:09,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:09,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:56:09,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:14,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:19,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:19,841] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:56:19,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:56:19,845] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:56:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:56:19,854] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:56:19,854] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:56:19,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:19,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:56:24,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:29,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:29,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:56:29,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:34,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:39,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:39,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:56:39,851] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:39,851] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:56:44,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:49,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:49,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:56:49,842] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:56:49,844] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:56:49,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:49,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:56:49,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:56:49,852] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:56:54,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:59,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:56:59,842] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:56:59,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:56:59,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:57:04,838] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:05,355] INFO  {NatTestLauncher} initiating
[15:57:05,586] INFO  {NatTestLauncher} starting
[15:57:05,681] INFO  {NatTestLauncher} waiting for nat
[15:57:05,688] INFO  {NatSetup} received local interfaces:[NI:name:en0 (en0) addr:/193.10.67.178 up:true mtu:1500 netPrefixLength:22, NI:name:lo0 (lo0) addr:/127.0.0.1 up:true mtu:16384 netPrefixLength:8]
[15:57:05,688] INFO  {NatSetup} multiple ips detected, proceeding with:/193.10.67.178
[15:57:05,688] INFO  {NatSetup} starting with local interface:/193.10.67.178
[15:57:05,700] INFO  {NatDetectionComp} 193.10.67.178:30000<1> initiating...
[15:57:05,702] INFO  {NatDetectionComp} 193.10.67.178:30000<1> starting...
[15:57:05,706] INFO  {StunClientComp} /193.10.67.178<43211,43210> initiating...
[15:57:05,713] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting...
[15:57:05,713] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[15:57:05,714] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[15:57:05,716] INFO  {UpnpComp} nat upnp initiating...
[15:57:05,718] INFO  {UpnpComp} nat upnp starting...
[15:57:05,753] DEBUG {UpnpComp} nat upnp :Device notified:M-SEARCH * HTTP/1.1
ST: upnp:rootdevice
MX: 3
MAN: "ssdp:discover"
HOST: 239.255.255.250:1900


[15:57:05,940] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[15:57:05,940] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[15:57:05,948] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting new echo session:5097db56-a7b4-4cec-a06b-cd1dec3faab5
[15:57:05,948] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server1:193.10.64.107:54321<-1> 193.10.64.107:54320<-1>
[15:57:05,949] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server2:193.10.64.85:54321<-2> 193.10.64.85:54320<-2>
[15:57:05,949] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:SIP_SP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[15:57:06,027] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:57:06,027] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:57:06,029] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:6361982a-e13d-4381-8f69-3acdbfd13362 - restarting hook...
[15:57:06,030] INFO  {StunClientComp} /193.10.67.178<43211,43210> tearing down hook2
[15:57:06,030] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[15:57:06,031] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[15:57:06,033] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:0f309d01-5ae5-48bc-976b-1918e20207ed - restarting hook...
[15:57:06,033] INFO  {StunClientComp} /193.10.67.178<43211,43210> tearing down hook1
[15:57:06,033] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[15:57:06,033] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[15:57:06,035] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:57:06,036] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:d969affb-fa79-48ae-b7bd-541bc6716e06 - restarting hook...
[15:57:06,036] INFO  {StunClientComp} /193.10.67.178<43211,43210> tearing down hook2
[15:57:06,036] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[15:57:06,036] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[15:57:06,038] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:57:06,039] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:a2cd549a-250a-426b-b1e1-547a610efabc - restarting hook...
[15:57:06,040] INFO  {StunClientComp} /193.10.67.178<43211,43210> tearing down hook1
[15:57:06,040] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[15:57:06,040] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[15:57:06,041] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:57:06,042] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:7b6154f6-545b-489c-b6c0-2db9516d930b - restarting hook...
[15:57:06,042] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[15:57:06,042] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:57:06,043] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:b0d2fde6-6071-48e5-a14c-69b4dc9f6c3c
[15:57:06,043] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(b0d2fde6-6071-48e5-a14c-69b4dc9f6c3c):se.sics.nat.stun.client.StunClientComp@43e00030 while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(7b6154f6-545b-489c-b6c0-2db9516d930b):se.sics.kompics.network.netty.NettyNetwork@510f2700 while handling event se.sics.kompics.Start@1c0d4492)) 


[15:57:09,840] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:09,841] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:57:09,854] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:57:14,839] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:19,836] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:19,837] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:57:19,837] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:57:19,845] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:57:19,852] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:57:19,853] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:57:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:57:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:57:19,853] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:57:24,356] INFO  {NatTestLauncher} initiating
[15:57:24,593] INFO  {NatTestLauncher} starting
[15:57:24,671] INFO  {NatTestLauncher} waiting for nat
[15:57:24,677] INFO  {NatSetup} received local interfaces:[NI:name:en0 (en0) addr:/193.10.67.178 up:true mtu:1500 netPrefixLength:22, NI:name:lo0 (lo0) addr:/127.0.0.1 up:true mtu:16384 netPrefixLength:8]
[15:57:24,677] INFO  {NatSetup} multiple ips detected, proceeding with:/193.10.67.178
[15:57:24,677] INFO  {NatSetup} starting with local interface:/193.10.67.178
[15:57:24,690] INFO  {NatDetectionComp} 193.10.67.178:30000<1> initiating...
[15:57:24,692] INFO  {NatDetectionComp} 193.10.67.178:30000<1> starting...
[15:57:24,694] INFO  {StunClientComp} /193.10.67.178<43211,43210> initiating...
[15:57:24,699] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting...
[15:57:24,699] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook1
[15:57:24,700] INFO  {NatSetup} binding on stun:193.10.67.178:43211<1>
[15:57:24,702] INFO  {UpnpComp} nat upnp initiating...
[15:57:24,706] INFO  {UpnpComp} nat upnp starting...
[15:57:24,743] DEBUG {UpnpComp} nat upnp :Device notified:M-SEARCH * HTTP/1.1
ST: upnp:rootdevice
MX: 3
MAN: "ssdp:discover"
HOST: 239.255.255.250:1900


[15:57:24,919] INFO  {StunClientComp} /193.10.67.178<43211,43210> setting up network hook2
[15:57:24,919] INFO  {NatSetup} binding on stun:193.10.67.178:43210<1>
[15:57:24,927] INFO  {StunClientComp} /193.10.67.178<43211,43210> starting new echo session:06d3d1bd-7263-49ca-9a7a-8b1dc4a4b688
[15:57:24,927] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server1:193.10.64.107:54321<-1> 193.10.64.107:54320<-1>
[15:57:24,928] INFO  {StunClientComp} /193.10.67.178<43211,43210> stun server2:193.10.64.85:54321<-2> 193.10.64.85:54320<-2>
[15:57:24,929] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:SIP_SP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[15:57:25,146] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<SIP_SP> from:193.10.64.107:54321<-1>
[15:57:25,156] DEBUG {StunClientComp} /193.10.67.178<43211,43210> sending:DIP_DP from:193.10.67.178:43211<1> to:193.10.64.107:54321<-1>
[15:57:25,195] DEBUG {StunClientComp} /193.10.67.178<43211,43210> received:STUN_ECHO_RESP<DIP_DP> from:193.10.64.85:54320<-2>
[15:57:25,196] INFO  {StunClientComp} /193.10.67.178<43211,43210> session result:OPEN
[15:57:25,197] INFO  {NatDetectionComp} 193.10.67.178:30000<1> nat detected:OP public ip:/193.10.67.178
[15:57:25,945] TRACE {Cybergarage} UP&P.getAddress() is called \o/
[15:57:25,946] DEBUG {Cybergarage} No UP&P device found, detection of the external ip address using the plugin has failed
[15:57:25,951] INFO  {NatDetectionComp} 193.10.67.178:30000<1> upnp ready:Optional.absent()
[15:57:25,952] INFO  {NatSetup} nat detected:OP public ip:/193.10.67.178 private ip:/193.10.67.178
[15:57:25,953] DEBUG {NatSetup} Initiating the binding on the socket to keep the port being used by some other service.
[15:57:25,953] DEBUG {NatSetup} Trying to bind on the socket1 with ip: /193.10.67.178 and port: 30000
[15:57:25,955] DEBUG {NatSetup} Socket successfully bound to ip :/193.10.67.178 and port: 30000
[15:57:25,955] DEBUG {NatSetup} {}Building the system configuration.
[15:57:25,966] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[15:57:25,982] INFO  {NatTestLauncher} nat started
[15:57:25,982] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting...
[15:57:25,983] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[15:57:25,983] INFO  {NatSetup} binding on nat:193.10.67.178:30000<1>OP
[15:57:25,984] INFO  {NatTestComp} initiating
[15:57:25,985] INFO  {NatTestComp} starting
[15:57:25,986] INFO  {NatTestComp} waiting for self address
[15:57:26,001] INFO  {PMServerComp} 193.10.67.178:30000<1> initiating...
[15:57:26,002] INFO  {PMServerComp} 193.10.67.178:30000<1> starting...
[15:57:26,008] INFO  {SHPClientComp} 193.10.67.178:30000<1> initiating...
[15:57:26,009] INFO  {SHPClientComp} 193.10.67.178:30000<1> starting...
[15:57:26,011] INFO  {HPServerComp} 193.10.67.178:30000<1> initiating...
[15:57:26,011] INFO  {HPServerComp} 193.10.67.178:30000<1> starting...
[15:57:31,008] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:36,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:36,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:57:36,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:57:41,007] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:46,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:46,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:57:46,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:57:46,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:57:51,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:56,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:57:56,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:57:56,007] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:57:56,010] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:57:56,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:57:56,013] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:57:56,014] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:57:56,014] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:58:01,008] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:06,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:06,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:58:06,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:58:06,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:58:11,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:16,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:16,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:58:16,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:58:21,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:26,008] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:26,009] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:58:26,009] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:58:26,010] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:58:26,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:58:26,013] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:58:26,013] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:58:26,013] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:58:26,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:58:31,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:36,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:36,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:58:36,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:58:41,007] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:46,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:46,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:58:46,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:58:46,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:58:51,008] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:56,007] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:58:56,007] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:58:56,007] INFO  {PMServerComp} 193.10.67.178:30000<1> internal state check - children:0, heartbeats:0
[15:58:56,009] INFO  {SHPClientComp} 193.10.67.178:30000<1> sessions - initiator:0 target:0
[15:58:56,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:58:56,014] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[15:58:56,014] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[15:58:56,014] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[15:59:01,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:59:05,502] INFO  {NatTestLauncher} initiating
[15:59:05,709] INFO  {NatTestLauncher} starting
[15:59:05,803] INFO  {NatTestLauncher} waiting for nat
[15:59:06,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:59:06,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat check
[15:59:06,013] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[15:59:06,014] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[15:59:06,122] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:59:06,122] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:59:06,125] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:ef7dd8a4-5ea4-45f1-8cf3-74013783592f - restarting hook...
[15:59:06,129] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:4ae3eb1a-1138-4481-ba7c-6052e5e45824 - restarting hook...
[15:59:06,131] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:59:06,132] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:93d99da1-8c0d-4469-bbb3-45334a7cb9a4 - restarting hook...
[15:59:06,134] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:59:06,135] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:a9fe55ef-944e-47e5-8d68-a9ba909d0dda - restarting hook...
[15:59:06,143] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[15:59:06,144] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:c5a8ef02-3066-4511-8a00-e135e82ab3eb - restarting hook...
[15:59:06,144] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[15:59:06,144] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[15:59:06,144] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:44e689d7-6a1b-4581-b92a-f6a3bcc2cf10
[15:59:06,145] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(44e689d7-6a1b-4581-b92a-f6a3bcc2cf10):se.sics.nat.stun.client.StunClientComp@3432f9bd while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(c5a8ef02-3066-4511-8a00-e135e82ab3eb):se.sics.kompics.network.netty.NettyNetwork@34142d0 while handling event se.sics.kompics.Start@48b0cae3)) 


[15:59:11,006] DEBUG {PMServerComp} 193.10.67.178:30000<1> periodic heartbeat
[15:59:39,485] INFO  {NatTestLauncher} initiating
[15:59:39,691] INFO  {NatTestLauncher} starting
[15:59:39,798] INFO  {NatTestLauncher} waiting for nat
[15:59:41,079] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[15:59:41,097] INFO  {NatTestLauncher} nat started
[15:59:41,097] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting...
[15:59:41,097] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[15:59:41,100] INFO  {NatTestComp} initiating
[15:59:41,101] INFO  {NatTestComp} starting
[15:59:41,101] INFO  {NatTestComp} waiting for self address
[15:59:51,130] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:00:01,132] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:00:01,132] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:00:11,131] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:00:11,131] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:00:11,131] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:00:11,132] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:00:21,130] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:00:21,131] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:00:31,132] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:00:41,131] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:00:41,131] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:00:41,132] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:00:41,132] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:00:41,132] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:00:51,130] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:01:01,133] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:01:01,133] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:01:11,132] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:01:11,132] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:01:11,132] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:01:11,132] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:01:21,133] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:01:21,133] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:01:31,131] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:01:48,618] INFO  {NatTestLauncher} initiating
[16:01:48,849] INFO  {NatTestLauncher} starting
[16:01:48,944] INFO  {NatTestLauncher} waiting for nat
[16:01:50,218] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[16:01:50,237] INFO  {NatTestLauncher} nat started
[16:01:50,238] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[16:01:50,238] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[16:01:50,241] INFO  {NatTestComp} initiating
[16:01:50,242] INFO  {NatTestComp} starting
[16:01:50,249] INFO  {NatTestComp} waiting for self address
[16:02:00,277] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:02:10,276] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:02:10,276] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:02:20,276] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:02:20,276] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:02:20,276] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:02:20,277] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:02:30,278] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:02:30,278] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:02:53,933] INFO  {NatTestLauncher} initiating
[16:02:54,128] INFO  {NatTestLauncher} starting
[16:02:54,222] INFO  {NatTestLauncher} waiting for nat
[16:02:55,508] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[16:02:55,534] INFO  {NatTestLauncher} nat started
[16:02:55,536] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[16:02:55,536] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[16:02:55,537] INFO  {NatTestComp} initiating
[16:02:55,538] INFO  {NatTestComp} starting
[16:02:55,542] INFO  {NatTestComp} waiting for self address
[16:03:05,568] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:03:15,567] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:03:15,567] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:03:25,567] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:03:25,567] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:03:25,567] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:03:25,567] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:03:35,570] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:03:35,571] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:03:45,569] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:03:51,091] INFO  {NatTestLauncher} initiating
[16:03:51,256] INFO  {NatTestLauncher} starting
[16:03:51,347] INFO  {NatTestLauncher} waiting for nat
[16:03:51,650] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:03:51,650] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:03:51,653] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:04bafeb6-eefb-415e-9961-68785a42a61f - restarting hook...
[16:03:51,657] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:db9e19c7-3969-452a-835a-eb5b1f7f8fcd - restarting hook...
[16:03:51,659] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:03:51,660] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:5fd5ea60-a943-4c8b-bc66-1d7513ff1561 - restarting hook...
[16:03:51,663] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:03:51,664] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:487aa4df-d59c-49ad-ad81-e1ff2bab8a0e - restarting hook...
[16:03:51,665] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:03:51,666] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:d701df49-2a7d-4d99-a7e2-af5c74f88129 - restarting hook...
[16:03:51,666] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[16:03:51,667] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[16:03:51,667] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:f6254e57-229a-4bf0-b7a6-d37d6a608688
[16:03:51,667] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(f6254e57-229a-4bf0-b7a6-d37d6a608688):se.sics.nat.stun.client.StunClientComp@c57fd83 while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(d701df49-2a7d-4d99-a7e2-af5c74f88129):se.sics.kompics.network.netty.NettyNetwork@3f4115de while handling event se.sics.kompics.Start@679f2391)) 


[16:03:55,566] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:03:55,567] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:03:55,567] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:03:55,567] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:03:55,568] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:04:08,012] INFO  {NatTestLauncher} initiating
[16:04:08,215] INFO  {NatTestLauncher} starting
[16:04:08,299] INFO  {NatTestLauncher} waiting for nat
[16:04:09,558] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[16:04:09,562] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[16:04:09,573] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[16:04:09,578] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[16:04:09,580] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[16:04:09,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[16:04:09,582] INFO  {NatTestLauncher} nat started
[16:04:09,582] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[16:04:09,587] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@38e8d11d
[16:04:09,587] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[16:04:09,587] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[16:04:09,587] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[16:04:09,587] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[16:04:09,587] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[16:04:09,587] INFO  {NatTestComp} initiating
[16:04:09,588] INFO  {NatTestComp} starting
[16:04:09,588] INFO  {NatTestComp} waiting for self address
[16:04:19,612] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:04:29,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:04:29,612] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:04:39,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:04:39,612] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:04:39,612] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:04:39,612] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:04:49,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:04:49,612] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:04:59,612] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:05:09,610] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:05:09,610] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:05:09,610] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:05:09,610] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:05:09,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:05:19,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:05:29,610] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[16:05:29,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:05:39,611] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:05:39,611] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[16:05:39,612] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[16:05:39,612] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[16:08:49,385] INFO  {NatTestLauncher} initiating
[16:08:49,646] INFO  {NatTestLauncher} starting
[16:08:49,774] INFO  {NatTestLauncher} waiting for nat
[16:08:51,069] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[16:08:51,078] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[16:08:51,097] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[16:08:51,105] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[16:08:51,107] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[16:08:51,107] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[16:08:51,108] INFO  {NatTestLauncher} nat started
[16:08:51,109] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[16:08:51,109] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@5e26b3b6
[16:08:51,114] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[16:08:51,114] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[16:08:51,114] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[16:08:51,114] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[16:08:51,114] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[16:08:51,114] INFO  {NatTestComp} initiating
[16:08:51,115] INFO  {NatTestComp} starting
[16:08:51,115] INFO  {NatTestComp} waiting for self address
[16:09:01,152] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:09:03,787] INFO  {NatTestLauncher} initiating
[16:09:04,004] INFO  {NatTestLauncher} starting
[16:09:04,123] INFO  {NatTestLauncher} waiting for nat
[16:09:04,467] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:09:04,467] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:09:04,471] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:8f832951-cb56-4d1a-a893-9a1f4587a067 - restarting hook...
[16:09:04,475] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:35544ece-1d28-4d9b-bf55-2ce097eeb212 - restarting hook...
[16:09:04,480] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:09:04,482] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:9d4d7373-c080-42e6-8977-30d1e22e32de - restarting hook...
[16:09:04,487] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:09:04,487] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:bf6689ec-9e97-4f00-a78e-14652d54add4 - restarting hook...
[16:09:04,489] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[16:09:04,491] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:1b2b06e0-c53c-44e7-b6c3-6bb63aeef1ab - restarting hook...
[16:09:04,492] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[16:09:04,492] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[16:09:04,493] ERROR {NatDetectionComp} 193.10.67.178:30001<2> fault:stun client hook fatal error - recurring errors on comp:566b4c5e-fb95-4dd7-b1d8-40cc9c83638c
[16:09:04,493] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(566b4c5e-fb95-4dd7-b1d8-40cc9c83638c):se.sics.nat.stun.client.StunClientComp@15b14bbd while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(1b2b06e0-c53c-44e7-b6c3-6bb63aeef1ab):se.sics.kompics.network.netty.NettyNetwork@640363be while handling event se.sics.kompics.Start@3119e7f5)) 


[16:09:11,153] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeating on open connections:0
[16:09:11,154] TRACE {NatTraverserComp} 193.10.67.178:30000<1> heartbeat check
[09:47:27,304] INFO  {NatTestLauncher} initiating
[09:47:27,510] INFO  {NatTestLauncher} starting
[09:47:27,587] ERROR {Config} Nat:missing configuration
[09:47:27,587] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'croupier.global'
	at se.sics.nat.NatInitHelper.<init>(NatInitHelper.java:89)
	at se.sics.nat.NatSetup.<init>(NatSetup.java:96)
	at se.sics.nattest.NatTestLauncher.connectNStartNat(NatTestLauncher.java:121)
	at se.sics.nattest.NatTestLauncher.access$300(NatTestLauncher.java:65)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:108)
	at se.sics.nattest.NatTestLauncher$1.handle(NatTestLauncher.java:103)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'croupier.global'
	at com.typesafe.config.impl.SimpleConfig.findKey(SimpleConfig.java:124)
	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:147)
	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:151)
	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:159)
	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:164)
	at com.typesafe.config.impl.SimpleConfig.getConfigNumber(SimpleConfig.java:179)
	at com.typesafe.config.impl.SimpleConfig.getInt(SimpleConfig.java:190)
	at se.sics.nat.NatInitHelper.<init>(NatInitHelper.java:53)
	... 13 more
[09:47:27,589] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'croupier.global' thrown in Component(2a342fcd-7975-4e2f-b329-059924a099a0):se.sics.nattest.NatTestLauncher@520508af while handling event se.sics.kompics.Start@1bf1a59e) 


[09:47:46,450] INFO  {NatTestLauncher} initiating
[09:47:46,636] INFO  {NatTestLauncher} starting
[09:47:46,713] INFO  {NatTestLauncher} waiting for nat
[09:47:47,974] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[09:47:47,991] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[09:47:47,996] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[09:47:47,997] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[09:47:47,998] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[09:47:47,999] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[09:47:47,999] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@5da8a358
[09:47:47,999] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[09:47:47,999] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[09:47:47,999] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[09:47:47,999] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[09:47:48,005] INFO  {NatTestComp} initiating
[09:47:48,007] INFO  {NatTestComp} starting
[09:47:48,008] INFO  {NatTestComp} waiting for self address
[10:10:06,152] INFO  {NatTestLauncher} initiating
[10:10:06,431] INFO  {NatTestLauncher} starting
[10:10:06,553] INFO  {NatTestLauncher} waiting for nat
[10:10:07,817] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[10:10:07,832] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[10:10:07,842] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[10:10:07,843] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[10:10:07,844] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[10:10:07,845] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[10:10:07,846] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@34bfc3c6
[10:10:07,846] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[10:10:07,846] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[10:10:07,846] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[10:10:07,846] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[10:10:07,848] INFO  {NatTestComp} initiating
[10:10:07,849] INFO  {NatTestComp} starting
[10:10:07,849] INFO  {NatTestComp} waiting for self address
[10:12:58,302] INFO  {NatTestLauncher} initiating
[10:12:58,495] INFO  {NatTestLauncher} starting
[10:12:58,574] INFO  {NatTestLauncher} waiting for nat
[10:12:58,889] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[10:12:58,889] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[10:12:58,891] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:67670b49-7bb2-4f56-a69d-7304bc1aa93b - restarting hook...
[10:12:58,895] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:98f7c2fc-7c57-4646-add1-09efc757f9cf - restarting hook...
[10:12:58,899] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[10:12:58,900] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:497c3e81-4764-494a-a121-87c4c91a155a - restarting hook...
[10:12:58,901] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[10:12:58,902] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:2cba79e0-2423-432e-995f-e493a3239602 - restarting hook...
[10:12:58,906] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[10:12:58,907] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:0fbcc0ca-f40f-4a52-9592-adcdbca70ced - restarting hook...
[10:12:58,907] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[10:12:58,907] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:352)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1200(StunClientComp.java:311)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:161)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[10:12:58,908] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:fff4c7a1-b075-4fc4-b259-dce132db2735
[10:12:58,908] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(fff4c7a1-b075-4fc4-b259-dce132db2735):se.sics.nat.stun.client.StunClientComp@7199fa23 while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(0fbcc0ca-f40f-4a52-9592-adcdbca70ced):se.sics.kompics.network.netty.NettyNetwork@1119157c while handling event se.sics.kompics.Start@510f5d2d)) 


[10:12:58,909] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[10:13:15,781] INFO  {NatTestLauncher} initiating
[10:13:15,995] INFO  {NatTestLauncher} starting
[10:13:16,091] INFO  {NatTestLauncher} waiting for nat
[10:13:18,358] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.IllegalStateException: Optional.get() cannot be called on an absent value
	at com.google.common.base.Absent.get(Absent.java:47)
	at se.sics.nat.stun.client.StunClientComp$EchoMngr.processResult(StunClientComp.java:243)
	at se.sics.nat.stun.client.StunClientComp$EchoMngr.access$1600(StunClientComp.java:167)
	at se.sics.nat.stun.client.StunClientComp$EchoMngr$1.handle(StunClientComp.java:205)
	at se.sics.nat.stun.client.StunClientComp$EchoMngr$1.handle(StunClientComp.java:188)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[10:13:18,361] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:Optional.get() cannot be called on an absent value on comp:12634703-6766-4ff0-a7de-0f4f34783f74
[10:13:18,362] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.IllegalStateException: Optional.get() cannot be called on an absent value thrown in Component(12634703-6766-4ff0-a7de-0f4f34783f74):se.sics.nat.stun.client.StunClientComp@3c910e06 while handling event se.sics.nat.stun.client.StunClientComp$EchoTimeout@c004e5b) 


[10:15:11,867] INFO  {NatTestLauncher} initiating
[10:15:12,059] INFO  {NatTestLauncher} starting
[10:15:12,130] INFO  {NatTestLauncher} waiting for nat
[10:15:13,385] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[10:15:13,394] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[10:15:13,405] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[10:15:13,412] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[10:15:13,413] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[10:15:13,414] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[10:15:13,414] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[10:15:13,414] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@3108fb2b
[10:15:13,415] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[10:15:13,415] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[10:15:13,415] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[10:15:13,415] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[10:15:13,415] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[10:15:13,415] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[10:15:13,419] INFO  {NatTestComp} initiating
[10:15:13,420] INFO  {NatTestComp} starting
[10:15:13,420] INFO  {NatTestComp} waiting for self address
[10:16:43,808] INFO  {NatTestLauncher} initiating
[10:16:44,002] INFO  {NatTestLauncher} starting
[10:16:44,124] INFO  {NatTestLauncher} waiting for nat
[10:16:45,409] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[10:16:45,414] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[10:16:45,424] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[10:16:45,430] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[10:16:45,432] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[10:16:45,434] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[10:16:45,436] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[10:16:45,437] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[10:16:45,437] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[10:16:45,437] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@3ec54d80
[10:16:45,437] INFO  {NatTraverserComp} 193.10.67.178:30000<1> setting up network
[10:16:45,438] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[10:16:45,438] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[10:16:45,439] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[10:16:45,442] INFO  {NatTestComp} initiating
[10:16:45,442] INFO  {NatTestComp} starting
[10:16:45,443] INFO  {NatTestComp} waiting for self address
[10:16:45,449] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting parent maker
[10:17:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[10:17:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[10:17:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[10:17:45,480] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[10:17:45,480] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[10:17:45,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[10:18:15,480] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[10:18:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[10:18:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[10:18:45,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[10:18:45,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[10:18:45,482] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[10:19:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[10:19:15,481] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[10:19:15,482] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[14:41:57,558] INFO  {NatTestLauncher} initiating
[14:41:57,565] INFO  {NatTestLauncher} starting
[14:41:57,673] INFO  {NatTestLauncher} waiting for nat
[14:41:57,969] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:41:57,969] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:41:57,971] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:e80c5ab5-150e-4961-b5fd-cbe502fd0775 - restarting hook...
[14:41:57,978] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:895448ea-f24e-4319-a883-94603e7e081f - restarting hook...
[14:41:57,982] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:41:57,982] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:a18421c0-8e4f-4336-80e0-6e5b02a63fb0 - restarting hook...
[14:41:57,984] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:41:57,985] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:7e64736f-d757-45ba-9e60-33014b557f62 - restarting hook...
[14:41:57,987] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:41:57,988] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:9e8821f8-bd8b-4404-a4a5-f2c3196c7978 - restarting hook...
[14:41:57,988] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[14:41:57,988] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:387)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1000(StunClientComp.java:314)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:164)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[14:41:57,988] ERROR {NatDetectionComp} 193.10.67.178:30000<1> fault:stun client hook fatal error - recurring errors on comp:b25a765c-ffe8-4bad-85d7-430883430e59
[14:41:57,989] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(b25a765c-ffe8-4bad-85d7-430883430e59):se.sics.nat.stun.client.StunClientComp@33bc8917 while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(9e8821f8-bd8b-4404-a4a5-f2c3196c7978):se.sics.kompics.network.netty.NettyNetwork@245ca11f while handling event se.sics.kompics.Start@467a7014)) 


[14:41:57,989] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:42:20,952] INFO  {NatTestLauncher} initiating
[14:42:20,956] INFO  {NatTestLauncher} starting
[14:42:21,026] INFO  {NatTestLauncher} waiting for nat
[14:42:22,486] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:42:22,492] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[14:42:22,502] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting network
[14:42:22,507] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting pm server
[14:42:22,511] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp server
[14:42:22,516] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp client
[14:42:22,525] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:42:22,532] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[14:42:22,534] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[14:42:22,534] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[14:42:22,535] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[14:42:22,535] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@5a897de9
[14:42:22,536] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:42:22,536] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[14:42:22,536] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[14:42:22,536] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:42:22,536] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[14:42:22,536] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting network
[14:42:22,538] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: Cannot create component se.sics.nattest.NatTestComp
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:214)
	at se.sics.kompics.ComponentDefinition.create(ComponentDefinition.java:195)
	at se.sics.nattest.NatTestLauncher.connectNStartApp(NatTestLauncher.java:108)
	at se.sics.nattest.NatTestLauncher.access$800(NatTestLauncher.java:65)
	at se.sics.nattest.NatTestLauncher$NatTestProxy.startApp(NatTestLauncher.java:124)
	at se.sics.nat.NatSetup.phase3(NatSetup.java:281)
	at se.sics.nat.NatSetup.access$1000(NatSetup.java:74)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:205)
	at se.sics.nat.NatSetup$3.handle(NatSetup.java:191)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.InstantiationException: se.sics.nattest.NatTestComp
	at java.lang.Class.newInstance(Class.java:418)
	at se.sics.kompics.JavaComponent.createInstance(JavaComponent.java:231)
	at se.sics.kompics.JavaComponent.doCreate(JavaComponent.java:203)
	... 16 more
Caused by: java.lang.NoSuchMethodException: se.sics.nattest.NatTestComp.<init>()
	at java.lang.Class.getConstructor0(Class.java:2971)
	at java.lang.Class.newInstance(Class.java:403)
	... 18 more
[14:42:22,541] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: Cannot create component se.sics.nattest.NatTestComp thrown in Component(d4366e81-643c-48a2-a1ae-0dd11762a557):se.sics.nattest.NatTestLauncher@c81229b while handling event se.sics.nat.stun.NatReady@1a6af792) 


[14:43:44,385] INFO  {NatTestLauncher} initiating
[14:43:44,388] INFO  {NatTestLauncher} starting
[14:43:44,466] INFO  {NatTestLauncher} waiting for nat
[14:43:45,925] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:43:45,930] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[14:43:45,939] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting network
[14:43:45,948] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting pm server
[14:43:45,953] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp server
[14:43:45,956] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp client
[14:43:45,966] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:43:45,982] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[14:43:45,983] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[14:43:45,983] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[14:43:45,984] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[14:43:45,985] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@2fe48f90
[14:43:45,985] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[14:43:45,985] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:43:45,985] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[14:43:45,985] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[14:43:45,985] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting network
[14:43:45,985] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:43:45,988] INFO  {NatTestComp} 193.10.67.178:30000<1>OPinitiating
[14:43:45,988] INFO  {NatTestComp} 193.10.67.178:30000<1>OPstarting
[14:43:53,012] INFO  {NatTestLauncher} initiating
[14:43:53,018] INFO  {NatTestLauncher} starting
[14:43:53,089] INFO  {NatTestLauncher} waiting for nat
[14:43:53,412] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:43:53,412] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:43:53,416] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:6362cf2e-10c6-414f-82f4-9513815f065f - restarting hook...
[14:43:53,419] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:745a7f81-8d35-4fe9-b14c-030cceab8d13 - restarting hook...
[14:43:53,422] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:43:53,423] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:8f5ae0f3-d5b6-413d-bb19-fbce70cca5d8 - restarting hook...
[14:43:53,426] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:43:53,428] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:e2a50502-dd08-485b-8882-cd2201e607f3 - restarting hook...
[14:43:53,433] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:414)
	at sun.nio.ch.Net.bind(Net.java:406)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:125)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:554)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1237)
	at io.netty.channel.ChannelHandlerInvokerUtil.invokeBindNow(ChannelHandlerInvokerUtil.java:109)
	at io.netty.channel.DefaultChannelHandlerInvoker.invokeBind(DefaultChannelHandlerInvoker.java:214)
	at io.netty.channel.PausableChannelEventExecutor.invokeBind(PausableChannelEventExecutor.java:101)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:481)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:1013)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:236)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:357)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.internal.chmv8.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1412)
	at io.netty.util.internal.chmv8.ForkJoinTask.doExec(ForkJoinTask.java:280)
	at io.netty.util.internal.chmv8.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:877)
	at io.netty.util.internal.chmv8.ForkJoinPool.scan(ForkJoinPool.java:1706)
	at io.netty.util.internal.chmv8.ForkJoinPool.runWorker(ForkJoinPool.java:1661)
	at io.netty.util.internal.chmv8.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:126)
[14:43:53,434] ERROR {StunClientComp} /193.10.67.178<43211,43210> fault:Address already in use from component:3999e202-dca0-40e3-84f3-1862cc512b38 - restarting hook...
[14:43:53,434] ERROR {StunClientComp} /193.10.67.178<43211,43210> stun client hook fatal error - recurring errors
[14:43:53,434] ERROR {Kompics} Handling an event caused a fault! Might be handled later...
java.lang.RuntimeException: stun client hook fatal error - recurring errors
	at se.sics.nat.stun.client.StunClientComp$HookTracker.restartHook(StunClientComp.java:387)
	at se.sics.nat.stun.client.StunClientComp$HookTracker.access$1000(StunClientComp.java:314)
	at se.sics.nat.stun.client.StunClientComp.handleFault(StunClientComp.java:164)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:440)
	at se.sics.kompics.JavaComponent$1.handle(JavaComponent.java:435)
	at se.sics.kompics.JavaComponent.executeEvent(JavaComponent.java:365)
	at se.sics.kompics.JavaComponent.execute(JavaComponent.java:309)
	at se.sics.kompics.Scheduler.executeComponent(Scheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler.access$100(ThreadPoolScheduler.java:15)
	at se.sics.kompics.scheduler.ThreadPoolScheduler$1.run(ThreadPoolScheduler.java:35)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[14:43:53,435] ERROR {NatDetectionComp} 193.10.67.178:30001<2> fault:stun client hook fatal error - recurring errors on comp:2a5508d4-50b7-4793-8366-c44b61d85780
[14:43:53,435] ERROR {Kompics} A fault was escalated to the root component: 
KompicsFault(java.lang.RuntimeException: stun client hook fatal error - recurring errors thrown in Component(2a5508d4-50b7-4793-8366-c44b61d85780):se.sics.nat.stun.client.StunClientComp@515e6fb while handling event KompicsFault(java.net.BindException: Address already in use thrown in Component(3999e202-dca0-40e3-84f3-1862cc512b38):se.sics.kompics.network.netty.NettyNetwork@2f167483 while handling event se.sics.kompics.Start@46f341a1)) 


[14:44:15,989] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection tracker - open:0 new:0
[14:44:15,990] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check connection maker - pending:0
[14:44:15,990] INFO  {NatTraverserComp} 193.10.67.178:30000<1> internal state check traffic tracker - buffering for targets:0
[14:44:50,642] INFO  {NatTestLauncher} initiating
[14:44:50,646] INFO  {NatTestLauncher} starting
[14:44:50,733] INFO  {NatTestLauncher} waiting for nat
[14:44:52,194] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:44:52,200] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[14:44:52,209] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting network
[14:44:52,214] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting pm server
[14:44:52,220] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp server
[14:44:52,225] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp client
[14:44:52,231] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:44:52,239] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[14:44:52,240] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[14:44:52,241] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[14:44:52,242] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[14:44:52,242] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@4edf2779
[14:44:52,242] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:44:52,242] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[14:44:52,242] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[14:44:52,242] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:44:52,242] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[14:44:52,243] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting network
[14:44:52,254] INFO  {NatTestComp} 193.10.67.178:30000<1>OPinitiating
[14:44:52,256] INFO  {NatTestComp} 193.10.67.178:30000<1>OPstarting
[14:44:57,986] INFO  {NatTestLauncher} initiating
[14:44:57,990] INFO  {NatTestLauncher} starting
[14:44:58,082] INFO  {NatTestLauncher} waiting for nat
[14:44:58,417] INFO  {NettyNetwork@43220} Successfully bound to ip:port /193.10.67.178:43220
[14:44:58,417] INFO  {NettyNetwork@43221} Successfully bound to ip:port /193.10.67.178:43221
[14:44:58,438] INFO  {NettyNetwork@43220} Successfully bound UDT to ip:port /193.10.67.178:55339 with config: {SO_RCVBUF=131072, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_HIGH_WATER_MARK=65536, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), WRITE_BUFFER_LOW_WATER_MARK=32768, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@6892760d, SO_REUSEADDR=true, SO_LINGER=0, SO_BACKLOG=64, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, WRITE_SPIN_COUNT=16, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@564bbecd, SO_SNDBUF=131072, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, MAX_MESSAGES_PER_READ=16, AUTO_READ=true}
[14:44:58,438] INFO  {NettyNetwork@43221} Successfully bound UDT to ip:port /193.10.67.178:56406 with config: {SO_RCVBUF=131072, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_HIGH_WATER_MARK=65536, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), WRITE_BUFFER_LOW_WATER_MARK=32768, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@6892760d, SO_REUSEADDR=true, SO_LINGER=0, SO_BACKLOG=64, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, WRITE_SPIN_COUNT=16, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@564bbecd, SO_SNDBUF=131072, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, MAX_MESSAGES_PER_READ=16, AUTO_READ=true}
[14:44:58,457] INFO  {NettyNetwork@43220} Successfully bound to ip:port /193.10.67.178:43220
[14:44:58,457] TRACE {NettyNetwork@43220} Channel connected: UDP /193.10.67.178:43220 => null ([id: 0xad75594e, /193.10.67.178:43220])
[14:44:58,457] TRACE {NettyNetwork@43221} Channel connected: UDP /193.10.67.178:43221 => null ([id: 0xde8007b1, /193.10.67.178:43221])
[14:44:58,457] INFO  {NettyNetwork@43221} Successfully bound to ip:port /193.10.67.178:43221
[14:44:58,493] DEBUG {NettyNetwork@43221} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@7362c553 (61bytes)
[14:44:58,530] DEBUG {NettyNetwork@43221} Delivering message STUN_ECHO_RESP<SIP_SP>from:193.10.64.107:54321<-1>to:193.10.67.178:43221<2> from 193.10.64.107:54321<-1> to 193.10.67.178:43221<2> protocol UDP
[14:44:58,547] DEBUG {NettyNetwork@43221} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@4b54eb66 (72bytes)
[14:44:58,555] DEBUG {NettyNetwork@43221} Delivering message STUN_ECHO_RESP<DIP_DP>from:193.10.64.85:54320<-2>to:193.10.67.178:43221<2> from 193.10.64.85:54320<-2> to 193.10.67.178:43221<2> protocol UDP
[14:44:59,568] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:44:59,573] INFO  {NatTraverserComp} 193.10.67.178:30001<2> initiating...
[14:44:59,581] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting network
[14:44:59,590] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting pm server
[14:44:59,595] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting hp server
[14:44:59,598] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting hp client
[14:44:59,606] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:44:59,613] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> initiating with bootstrap nodes:[] ...
[14:44:59,614] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> subscribing
[14:44:59,614] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> subscribed
[14:44:59,615] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> starting...
[14:44:59,615] INFO  {NatTestLauncher} nat started with:193.10.67.178:30001<2>OP
[14:44:59,615] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@1be010d2
[14:44:59,615] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> no partners - not shuffling
[14:44:59,616] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> joining using nodes:[193.10.67.178:30000<1>OP]
[14:44:59,616] INFO  {NatTraverserComp} 193.10.67.178:30001<2> starting with self:193.10.67.178:30001<2>OP
[14:44:59,616] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> started shuffle
[14:44:59,616] INFO  {NatTraverserComp} 193.10.67.178:30001<2> starting network
[14:44:59,617] INFO  {NatTestComp} 193.10.67.178:30001<2>OPinitiating
[14:44:59,618] INFO  {NatTestComp} 193.10.67.178:30001<2>OPstarting
[14:44:59,618] INFO  {NettyNetwork@30001} Successfully bound to ip:port /193.10.67.178:30001
[14:44:59,625] INFO  {NettyNetwork@30001} Successfully bound UDT to ip:port /193.10.67.178:65200 with config: {SO_RCVBUF=131072, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, CONNECT_TIMEOUT_MILLIS=30000, WRITE_BUFFER_HIGH_WATER_MARK=65536, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), WRITE_BUFFER_LOW_WATER_MARK=32768, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@6892760d, SO_REUSEADDR=true, SO_LINGER=0, SO_BACKLOG=64, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, WRITE_SPIN_COUNT=16, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@564bbecd, SO_SNDBUF=131072, io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, MAX_MESSAGES_PER_READ=16, AUTO_READ=true}
[14:44:59,627] INFO  {NettyNetwork@30001} Successfully bound to ip:port /193.10.67.178:30001
[14:44:59,627] TRACE {NettyNetwork@30001} Channel connected: UDP /193.10.67.178:30001 => null ([id: 0xc95c47ff, /193.10.67.178:30001])
[14:45:01,619] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:0, private view size:0, bootstrap nodes size:1
[14:45:01,619] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:0
[14:45:01,622] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:01,657] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@8047f03 (74bytes)
[14:45:01,674] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:01,675] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:01,676] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:01,676] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> started shuffle
[14:45:01,715] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:01,716] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,619] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:03,620] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:03,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:03,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:03,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:03,622] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:03,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[]
[14:45:03,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:03,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:03,624] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4616ea01from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:03,625] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@425be38a (93bytes)
[14:45:03,626] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@7f748ebf (33bytes)
[14:45:03,636] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:03,636] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@4d97c58bfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:03,636] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:45:03,637] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,663] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:03,664] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,677] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:03,678] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:03,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:03,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:03,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:03,679] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[]
[14:45:03,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:03,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:03,681] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4cf7dcbfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,682] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:03,683] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,683] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@54232c02from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:03,683] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@54232c02from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:03,683] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:03,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:03,701] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@48d10cb3 (93bytes)
[14:45:03,702] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:05,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:05,622] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:05,623] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:05,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:05,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:05,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:05,624] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:05,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:05,625] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:05,625] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@17cfe6dbfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:05,626] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@13325cc2 (93bytes)
[14:45:05,627] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@38e5c5c0 (33bytes)
[14:45:05,628] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:05,629] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@3cbb1ab2from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:05,629] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:45:05,629] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:05,630] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:05,631] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:05,680] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:05,680] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:05,680] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:05,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:05,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:05,681] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:05,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:05,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:05,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:05,682] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@607778bafrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:05,684] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:05,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:05,684] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@61983e6afrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:05,684] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:45:05,685] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@61983e6afrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:05,685] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:05,686] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@a95001b (93bytes)
[14:45:05,687] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:07,620] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:07,620] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:07,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:07,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:07,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:07,621] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:07,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:07,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:07,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:07,622] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@13e98e71from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:07,622] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@51cf6680 (93bytes)
[14:45:07,622] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@2a7c7cc0 (33bytes)
[14:45:07,623] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:07,623] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@7d2e9af9from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:07,623] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:45:07,624] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:07,625] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:07,625] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:07,678] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:07,678] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:07,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:07,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:07,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:07,679] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:07,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:07,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:07,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:07,680] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4056eb9afrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:07,681] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:07,682] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:07,682] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@4a9a046dfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:07,682] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:07,682] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@4a9a046dfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:07,682] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:07,683] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@6a024480 (93bytes)
[14:45:07,684] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:09,620] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:09,621] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:09,622] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:09,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:09,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:09,623] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:09,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:09,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:09,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:09,625] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@5ae5ba6ffrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:09,639] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@5a84a95b (93bytes)
[14:45:09,641] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@6b14930d (33bytes)
[14:45:09,643] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:09,643] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@16609a54from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:09,643] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:45:09,644] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:09,645] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:09,646] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:09,678] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:09,678] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:09,678] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:09,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:09,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:09,679] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:09,679] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:09,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:09,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:09,680] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@5864df33from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:09,681] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:09,682] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:09,682] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@401adeacfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:09,682] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:45:09,682] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@401adeacfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:09,682] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:09,683] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@426dbe6a (93bytes)
[14:45:09,700] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:11,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:11,621] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:11,622] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:11,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:11,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:11,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:11,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:11,624] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:11,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:11,625] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@106ce046from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:11,626] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@35434af7 (93bytes)
[14:45:11,628] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@b5090a9 (33bytes)
[14:45:11,630] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:11,631] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@d0e6ad7from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:11,631] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:45:11,631] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:11,633] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:11,634] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:11,681] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:11,682] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:11,682] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:11,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:11,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:11,682] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:11,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:11,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:11,683] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:11,683] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@dc5536cfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:11,684] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:11,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:11,684] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@56d9f073from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:11,684] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:45:11,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@56d9f073from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:11,685] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:11,685] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@5bd5f5c1 (93bytes)
[14:45:11,686] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:13,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:13,621] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:13,622] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:13,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:13,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:13,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:13,623] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:13,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:13,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:13,624] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@6e2c1c50from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:13,625] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@69ddc2ff (93bytes)
[14:45:13,625] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@14c24558 (33bytes)
[14:45:13,626] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:13,627] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@588af0aafrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:13,627] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:13,627] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:13,629] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:13,630] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:13,683] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:13,683] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:13,683] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:13,683] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:13,684] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:13,684] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:13,684] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:13,684] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:13,684] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:13,685] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@789a1014from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:13,686] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:13,686] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:13,686] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@7347a2dffrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:13,686] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:45:13,686] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@7347a2dffrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:13,687] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:13,687] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@19b5bf03 (93bytes)
[14:45:13,689] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:15,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:15,621] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:15,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:15,621] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:15,622] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:15,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:15,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:15,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:15,625] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:15,625] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@fbfb192from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:15,626] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@60daebe4 (93bytes)
[14:45:15,626] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@4a8b6a19 (33bytes)
[14:45:15,628] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:15,629] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:15,629] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@27dd8f25from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:15,629] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:15,631] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:15,631] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:15,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:15,679] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:15,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:15,680] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:15,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:15,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:15,680] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:15,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:15,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:15,681] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4cecea29from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:15,683] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:15,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:15,684] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@17c704a3from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:15,684] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:45:15,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@17c704a3from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:15,685] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:15,685] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@787e54c8 (93bytes)
[14:45:15,686] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:17,618] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:17,618] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:17,618] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:17,618] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:17,618] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:17,619] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:17,619] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:17,619] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:17,619] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:17,619] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@3d885f4from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:17,620] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@19710e40 (93bytes)
[14:45:17,620] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@66c0a244 (33bytes)
[14:45:17,621] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:17,621] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@2f7f3b83from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:17,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:45:17,622] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:17,623] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:17,624] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:17,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:17,679] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:17,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:17,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:17,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:17,680] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:17,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:17,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:17,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:17,682] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4bedcbe2from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:17,683] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:17,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:17,684] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@5b28d895from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:17,684] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:17,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@5b28d895from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:17,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:17,686] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@2ce9e50b (93bytes)
[14:45:17,687] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:19,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:19,622] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:19,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:19,623] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:19,623] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:19,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:19,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:19,624] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:19,630] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:19,630] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@69b78e30from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:19,631] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@7b1fa593 (93bytes)
[14:45:19,631] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@4a001d5a (33bytes)
[14:45:19,631] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:19,632] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@704d180afrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:19,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:19,632] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:19,633] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:19,633] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:19,680] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:19,681] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:19,681] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:19,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:19,681] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:19,681] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:19,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:19,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:19,682] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:45:19,682] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4a96350bfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:19,684] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:19,684] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:19,684] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@6734aba2from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:45:19,684] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:45:19,685] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@6734aba2from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:19,685] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:19,686] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@439e4d3 (93bytes)
[14:45:19,687] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:21,621] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:21,621] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:45:21,622] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:45:21,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:45:21,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:45:21,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:45:21,622] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:45:21,622] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:45:21,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:45:21,679] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:45:21,679] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:45:21,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:45:21,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:45:21,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:45:21,680] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:45:21,680] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:45:26,627] WARN  {Kompics} Failed orderly Kompics shutdown
[14:45:26,627] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:45:26,684] WARN  {Kompics} Failed orderly Kompics shutdown
[14:45:26,684] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:05,520] INFO  {NatTestLauncher} initiating
[14:46:05,526] INFO  {NatTestLauncher} starting
[14:46:05,596] INFO  {NatTestLauncher} waiting for nat
[14:46:07,059] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:46:07,064] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[14:46:07,071] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting network
[14:46:07,076] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting pm server
[14:46:07,081] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp server
[14:46:07,085] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp client
[14:46:07,092] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:46:07,098] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[14:46:07,099] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[14:46:07,100] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[14:46:07,102] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[14:46:07,102] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@2d8159c2
[14:46:07,103] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:46:07,103] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[14:46:07,103] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[14:46:07,104] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting network
[14:46:07,104] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:46:07,109] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[14:46:07,111] INFO  {NatTestComp} 193.10.67.178:30000<1>OPinitiating
[14:46:07,112] INFO  {NatTestComp} 193.10.67.178:30000<1>OPstarting
[14:46:12,985] INFO  {NatTestLauncher} initiating
[14:46:12,989] INFO  {NatTestLauncher} starting
[14:46:13,061] INFO  {NatTestLauncher} waiting for nat
[14:46:14,526] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:46:14,529] INFO  {NatTraverserComp} 193.10.67.178:30001<2> initiating...
[14:46:14,541] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting network
[14:46:14,547] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting pm server
[14:46:14,551] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting hp server
[14:46:14,554] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting hp client
[14:46:14,566] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:46:14,570] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> initiating with bootstrap nodes:[] ...
[14:46:14,571] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> subscribing
[14:46:14,572] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> subscribed
[14:46:14,572] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> starting...
[14:46:14,573] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@482c4128
[14:46:14,573] INFO  {NatTestLauncher} nat started with:193.10.67.178:30001<2>OP
[14:46:14,573] INFO  {NatTraverserComp} 193.10.67.178:30001<2> starting with self:193.10.67.178:30001<2>OP
[14:46:14,573] INFO  {NatTraverserComp} 193.10.67.178:30001<2> starting network
[14:46:14,575] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> no partners - not shuffling
[14:46:14,575] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> joining using nodes:[193.10.67.178:30000<1>OP]
[14:46:14,575] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> started shuffle
[14:46:14,575] INFO  {NettyNetwork@30001} Successfully bound to ip:port /193.10.67.178:30001
[14:46:14,577] INFO  {NatTestComp} 193.10.67.178:30001<2>OPinitiating
[14:46:14,577] INFO  {NatTestComp} 193.10.67.178:30001<2>OPstarting
[14:46:14,578] INFO  {NettyNetwork@30001} Successfully bound UDT to ip:port /193.10.67.178:58426 with config: {SO_REUSEADDR=true, SO_SNDBUF=131072, WRITE_BUFFER_LOW_WATER_MARK=32768, SO_LINGER=0, RCVBUF_ALLOCATOR=io.netty.channel.AdaptiveRecvByteBufAllocator@6a84ea5f, CONNECT_TIMEOUT_MILLIS=30000, io.netty.channel.udt.UdtChannelOption#PROTOCOL_SEND_BUFFER_SIZE=10485760, ALLOCATOR=PooledByteBufAllocator(directByDefault: true), io.netty.channel.udt.UdtChannelOption#SYSTEM_RECEIVE_BUFFER_SIZE=1048576, SO_BACKLOG=64, WRITE_BUFFER_HIGH_WATER_MARK=65536, MAX_MESSAGES_PER_READ=16, WRITE_SPIN_COUNT=16, io.netty.channel.udt.UdtChannelOption#PROTOCOL_RECEIVE_BUFFER_SIZE=10485760, MESSAGE_SIZE_ESTIMATOR=io.netty.channel.DefaultMessageSizeEstimator@59880329, AUTO_READ=true, io.netty.channel.udt.UdtChannelOption#SYSTEM_SEND_BUFFER_SIZE=1048576, SO_RCVBUF=131072}
[14:46:14,579] INFO  {NettyNetwork@30001} Successfully bound to ip:port /193.10.67.178:30001
[14:46:14,579] TRACE {NettyNetwork@30001} Channel connected: UDP /193.10.67.178:30001 => null ([id: 0x199b4ee9, /193.10.67.178:30001])
[14:46:16,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:0, private view size:0, bootstrap nodes size:1
[14:46:16,583] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:0
[14:46:16,586] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:16,608] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@76565f2f (74bytes)
[14:46:16,626] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:16,627] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:16,627] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:16,628] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> started shuffle
[14:46:16,660] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:16,661] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,579] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:18,579] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:18,580] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:18,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:18,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:18,580] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:18,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[]
[14:46:18,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:18,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:18,581] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@19418ec2from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:18,582] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@49a64b09 (93bytes)
[14:46:18,584] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@69a2a0e3 (33bytes)
[14:46:18,586] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:18,587] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@1ec3ef7efrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:18,587] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:46:18,587] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,601] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:18,602] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,633] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:18,634] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:18,635] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:18,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:18,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:18,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[]
[14:46:18,636] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:18,638] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:18,638] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@47801394from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,640] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:18,641] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,641] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@77b0c72dfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:18,641] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:18,642] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@77b0c72dfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:18,642] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:18,658] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@1786639a (93bytes)
[14:46:18,659] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:20,577] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:20,577] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:20,577] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:20,577] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:20,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:20,578] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:20,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:20,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:20,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:20,579] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@7438dd04from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:20,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@3c468349 (93bytes)
[14:46:20,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@782d0cc9 (33bytes)
[14:46:20,581] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:20,581] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@1c194c55from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:20,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:20,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:20,594] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:20,594] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:20,633] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:20,634] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:20,634] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:20,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:20,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:20,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:20,635] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:20,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:20,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:20,636] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@3a56c63efrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:20,638] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:20,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:20,639] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@6a9807e0from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:20,639] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:20,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@6a9807e0from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:20,640] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:20,641] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@f3d2e89 (93bytes)
[14:46:20,642] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:22,580] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:22,580] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:22,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:22,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:22,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:22,581] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:22,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:22,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:22,582] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:22,582] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@796c1c35from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:22,598] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@4b3f333f (93bytes)
[14:46:22,598] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@6ab40a00 (33bytes)
[14:46:22,601] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:22,602] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@587a381cfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:22,602] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:22,602] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:22,605] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:22,605] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:22,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:22,633] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:22,633] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:22,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:22,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:22,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:22,634] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:22,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:22,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:22,635] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@43ea21f1from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:22,637] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:22,637] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@a7f596dfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:22,637] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:22,638] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:22,638] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@a7f596dfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:22,638] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:22,639] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@5ed042fa (93bytes)
[14:46:22,640] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:24,578] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:24,578] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:24,578] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:24,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:24,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:24,579] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:24,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:24,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:24,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:24,580] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@13b9e5b2from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:24,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@73e42235 (93bytes)
[14:46:24,581] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@33e2cf74 (33bytes)
[14:46:24,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:24,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@e82835from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:24,582] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:46:24,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:24,584] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:24,584] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:24,634] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:24,635] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:24,635] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:24,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:24,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:24,635] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:24,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:24,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:24,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:24,636] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@78d8f9bbfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:24,637] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:24,637] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:24,637] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@6d3e47f7from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:24,638] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:24,638] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@6d3e47f7from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:24,638] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:24,639] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@180f4f1 (93bytes)
[14:46:24,639] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:26,578] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:26,578] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:26,579] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:26,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:26,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:26,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:26,579] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:26,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:26,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:26,580] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@43cbad0efrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:26,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@549070e0 (93bytes)
[14:46:26,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@7589a108 (33bytes)
[14:46:26,581] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:26,582] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:46:26,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@1c68ef3ffrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:26,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:26,585] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:26,586] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:26,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:26,633] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:26,633] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:26,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:26,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:26,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:26,634] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:26,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:26,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:26,634] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@9defbe8from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:26,635] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:26,636] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:26,636] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@114eefa4from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:26,636] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:26,636] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@114eefa4from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:26,637] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:26,637] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@715fd883 (93bytes)
[14:46:26,638] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:28,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:28,581] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:28,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:28,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:28,581] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:28,581] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:28,582] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:28,582] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:28,582] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:28,582] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@67afdb2efrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:28,583] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@1e00b88c (93bytes)
[14:46:28,584] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@7d3c6fa2 (33bytes)
[14:46:28,586] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:28,586] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@51035956from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:28,586] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:46:28,588] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:28,593] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:28,594] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:28,634] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:28,635] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:28,636] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:28,636] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:28,637] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:28,637] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:28,637] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:28,638] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:28,638] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:28,639] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@4adcaa30from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:28,641] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:28,641] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:28,641] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@1167c381from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:28,642] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:28,642] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@1167c381from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:28,642] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:28,643] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@3588a864 (93bytes)
[14:46:28,644] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:30,578] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:30,578] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:30,579] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:30,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:30,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:30,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:30,579] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:30,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:30,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:30,580] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@10b448cefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:30,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@2afc0795 (93bytes)
[14:46:30,580] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@12457223 (33bytes)
[14:46:30,581] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:30,581] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@475baa67from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:30,581] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:30,582] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:30,583] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:30,584] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:30,633] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:30,634] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:30,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:30,634] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:30,634] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:30,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:30,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:30,635] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:30,635] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:30,636] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@6aea76effrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:30,638] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:30,639] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@e053c95from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:30,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:30,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@e053c95from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:30,639] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:30,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:30,640] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@91a7c3f (93bytes)
[14:46:30,641] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:32,579] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:32,579] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:32,580] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:32,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:32,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:32,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:32,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:32,580] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:32,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:32,581] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@16951155 (93bytes)
[14:46:32,582] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@56bb69a1from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:32,583] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@4319ca2a (33bytes)
[14:46:32,584] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:32,585] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@497c72e5from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:32,585] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:46:32,586] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:32,589] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:32,590] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:32,631] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:32,632] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:32,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:32,632] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:32,632] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:32,632] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:32,632] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:32,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:32,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:32,634] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@a433a0afrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:32,637] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:32,638] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:32,639] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@4149c2f8from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:32,639] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:46:32,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@4149c2f8from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:32,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:32,642] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@3b7128a2 (93bytes)
[14:46:32,643] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:34,579] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:34,579] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:34,579] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:34,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:34,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:34,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:34,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:34,580] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:34,584] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:34,585] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@11b102c5from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:34,586] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@48ffc47e (93bytes)
[14:46:34,586] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@46f2e1fe (33bytes)
[14:46:34,588] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:34,589] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@7a829f50from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:34,589] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:34,589] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:34,591] DEBUG {NettyNetwork@30001} Delivering message ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:34,591] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:34,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:34,632] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:34,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:34,632] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:34,632] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:34,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:34,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:34,633] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:34,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:46:34,634] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@fa61d30from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:34,635] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:34,637] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:34,638] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:34,638] DEBUG {NettyNetwork@30001} Delivering message se.sics.nattest.msg.NatTestMsg$Ping@1f3a0055from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:34,639] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:34,640] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@1f3a0055from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:34,641] DEBUG {NettyNetwork@30001} Sending Datagram message se.sics.kompics.network.MessageNotify$Req@33508b4e (93bytes)
[14:46:34,652] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:36,577] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:36,578] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:46:36,578] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:46:36,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:46:36,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:46:36,578] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:46:36,578] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:46:36,579] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:46:36,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:46:36,632] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:46:36,632] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:46:36,632] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:46:36,633] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:46:36,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:46:36,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:46:36,633] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:46:36,634] DEBUG {NettyNetwork@30001} Delivering message ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP from 193.10.67.178:30000<1>OP to 193.10.67.178:30001<2>OP protocol UDP
[14:46:41,583] WARN  {Kompics} Failed orderly Kompics shutdown
[14:46:41,583] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:46:41,636] WARN  {Kompics} Failed orderly Kompics shutdown
[14:46:41,637] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:49:50,158] INFO  {NatTestLauncher} initiating
[14:49:50,163] INFO  {NatTestLauncher} starting
[14:49:50,276] INFO  {NatTestLauncher} waiting for nat
[14:49:51,797] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:49:51,806] INFO  {NatTraverserComp} 193.10.67.178:30000<1> initiating...
[14:49:51,817] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting network
[14:49:51,829] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting pm server
[14:49:51,833] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp server
[14:49:51,835] INFO  {NatTraverserComp} 193.10.67.178:30000<1> connecting hp client
[14:49:51,844] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:49:51,849] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> initiating with bootstrap nodes:[] ...
[14:49:51,850] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribing
[14:49:51,852] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> subscribed
[14:49:51,854] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> starting...
[14:49:51,854] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@1b1da8d9
[14:49:51,855] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:49:51,855] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting with self:193.10.67.178:30000<1>OP
[14:49:51,855] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> joining using nodes:[]
[14:49:51,855] INFO  {NatTraverserComp} 193.10.67.178:30000<1> starting network
[14:49:51,856] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:49:51,860] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[14:49:51,865] INFO  {NatTestComp} 193.10.67.178:30000<1>OPinitiating
[14:49:51,866] INFO  {NatTestComp} 193.10.67.178:30000<1>OPstarting
[14:49:57,957] INFO  {NatTestLauncher} initiating
[14:49:57,961] INFO  {NatTestLauncher} starting
[14:49:58,057] INFO  {NatTestLauncher} waiting for nat
[14:49:59,559] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:49:59,566] INFO  {NatTraverserComp} 193.10.67.178:30001<2> initiating...
[14:49:59,575] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting network
[14:49:59,580] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting pm server
[14:49:59,584] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting hp server
[14:49:59,588] INFO  {NatTraverserComp} 193.10.67.178:30001<2> connecting hp client
[14:49:59,595] INFO  {CroupierConfig} policy:RANDOM view size:5 shuffle size:5 period:2000 timeout:1000 softMaxTemperature:500.0
[14:49:59,601] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> initiating with bootstrap nodes:[] ...
[14:49:59,603] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> subscribing
[14:49:59,604] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> subscribed
[14:49:59,606] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> starting...
[14:49:59,606] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> updating selfView:se.sics.nat.common.croupier.GlobalCroupierView@35311997
[14:49:59,607] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> no partners - not shuffling
[14:49:59,607] INFO  {NatTestLauncher} nat started with:193.10.67.178:30001<2>OP
[14:49:59,607] INFO  {NatTraverserComp} 193.10.67.178:30001<2> starting with self:193.10.67.178:30001<2>OP
[14:49:59,607] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> joining using nodes:[193.10.67.178:30000<1>OP]
[14:49:59,608] INFO  {NatTraverserComp} 193.10.67.178:30001<2> starting network
[14:49:59,608] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> started shuffle
[14:49:59,613] INFO  {NatTestComp} 193.10.67.178:30001<2>OPinitiating
[14:49:59,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPstarting
[14:50:01,610] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:0, private view size:0, bootstrap nodes size:1
[14:50:01,612] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:0
[14:50:01,613] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:01,683] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:01,685] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:01,693] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:01,693] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> started shuffle
[14:50:01,736] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,611] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:03,611] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:03,612] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:03,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:03,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:03,612] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[]
[14:50:03,613] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:50:03,613] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:50:03,613] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@77a6b31efrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,615] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,616] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@7b265121from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,616] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:03,616] INFO  {NatTestComp} 193.10.67.178:30000<1>OPping from:193.10.67.178:30001<2>OP on:193.10.67.178:30000<1>OP
[14:50:03,617] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,617] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Pong@cdd1132from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,633] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,634] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Pong@f32d37ffrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,634] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpong from:193.10.67.178:30000<1>OP on:193.10.67.178:30001<2>OP
[14:50:03,697] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:03,698] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:03,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:03,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:03,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:03,698] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[]
[14:50:03,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:50:03,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:50:03,699] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@7909ed20from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,701] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,701] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@4845f8dbfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:03,701] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:03,702] INFO  {NatTestComp} 193.10.67.178:30001<2>OPping from:193.10.67.178:30000<1>OP on:193.10.67.178:30001<2>OP
[14:50:03,703] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,703] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Pong@7c725743from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,707] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,707] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Pong@3387575dfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:03,707] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpong from:193.10.67.178:30001<2>OP on:193.10.67.178:30000<1>OP
[14:50:05,614] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:05,614] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:05,615] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:05,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:05,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:05,615] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:05,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:05,616] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:05,632] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:05,633] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:05,633] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:05,646] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:05,699] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:05,699] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:05,700] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:05,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:05,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:05,700] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:05,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:05,701] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:05,706] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:05,707] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:50:05,708] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:05,711] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:07,610] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:07,611] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:07,611] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:07,611] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:07,611] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:07,612] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:07,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:07,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:07,640] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:07,641] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:50:07,641] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:07,646] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:07,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:07,698] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:07,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:07,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:07,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:07,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:07,699] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:07,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:07,701] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:07,702] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:07,702] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:07,706] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:09,616] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:09,617] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:09,617] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:09,617] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:09,618] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:09,618] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:09,618] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:09,618] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:09,622] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:09,623] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:50:09,623] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:09,626] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:09,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:09,698] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:09,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:09,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:09,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:09,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:09,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:09,698] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:09,701] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:09,701] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:09,701] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:09,703] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:11,613] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:11,613] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:11,613] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:11,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:11,614] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:11,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:11,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:11,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:11,615] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:11,616] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:11,616] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:11,617] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:11,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:11,698] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:11,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:11,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:11,698] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:11,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:11,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:11,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:11,700] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:11,701] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:50:11,701] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:11,702] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:13,615] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:13,615] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:13,615] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:13,616] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:13,616] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:13,616] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:13,616] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:13,617] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:13,618] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:13,619] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:13,619] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:13,621] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:13,696] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:13,696] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:13,697] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:13,697] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:13,697] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:13,697] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:13,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:13,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:13,699] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:13,700] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:50:13,700] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:13,702] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:15,613] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:15,613] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:15,613] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:15,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:15,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:15,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:15,614] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:15,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:15,617] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:15,617] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:15,617] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:15,619] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:15,699] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:15,700] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:15,700] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:15,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:15,700] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:15,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:15,701] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:15,701] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:15,702] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:15,703] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:15,703] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:15,704] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:17,614] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:17,614] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:17,615] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:17,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:17,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:17,615] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:17,615] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:17,616] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:17,618] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:17,618] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:50:17,618] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:17,620] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:17,697] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:17,697] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:17,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:17,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:17,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:17,698] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:17,698] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:17,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:17,700] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:17,700] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30000<1>OP:0>, <193.10.67.178:30001<2>OP:1>] 
 private nodes:[]
[14:50:17,700] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:17,702] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:19,610] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:19,610] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:19,611] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:19,611] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:19,611] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:19,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:19,612] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:19,617] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:19,618] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:19,619] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30000<1>OP:1>, <193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:19,619] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:19,620] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:19,699] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:19,700] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:19,700] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:19,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:19,700] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:19,700] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:19,701] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:19,701] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:19,702] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:19,703] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> received from:193.10.67.178:30000<1>OP 
 public nodes:[<193.10.67.178:30001<2>OP:1>, <193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:19,703] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:19,705] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:21,613] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:21,613] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> publishing sample 
 public nodes:[<193.10.67.178:30000<1>OP:0>] 
 private nodes:[]
[14:50:21,613] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> did not pick a public node for shuffling - public view size:1
[14:50:21,613] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:50:21,613] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:50:21,613] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:21,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:50:21,614] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:50:21,617] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:50:21,617] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> received from:193.10.67.178:30001<2>OP 
 public nodes:[<193.10.67.178:30001<2>OP:0>, <193.10.67.178:30000<1>OP:1>] 
 private nodes:[]
[14:50:21,617] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:21,698] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> public view size:1, private view size:0, bootstrap nodes size:0
[14:50:21,698] INFO  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> publishing sample 
 public nodes:[<193.10.67.178:30001<2>OP:0>] 
 private nodes:[]
[14:50:21,699] DEBUG {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> did not pick a public node for shuffling - public view size:1
[14:50:21,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:50:21,699] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:50:21,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:50:21,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:50:21,699] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:50:26,618] WARN  {Kompics} Failed orderly Kompics shutdown
[14:50:26,704] WARN  {Kompics} Failed orderly Kompics shutdown
[14:51:55,353] INFO  {NatTestLauncher} initiating
[14:51:55,357] INFO  {NatTestLauncher} starting
[14:51:55,451] INFO  {NatTestLauncher} waiting for nat
[14:51:56,993] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:51:56,994] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30000<1>> no partners - not shuffling
[14:51:56,994] INFO  {NatTestLauncher} nat started with:193.10.67.178:30000<1>OP
[14:51:57,000] INFO  {NatTestComp} 193.10.67.178:30000<1>OPinitiating
[14:51:57,001] INFO  {NatTestComp} 193.10.67.178:30000<1>OPstarting
[14:52:07,397] INFO  {NatTestLauncher} initiating
[14:52:07,401] INFO  {NatTestLauncher} starting
[14:52:07,476] INFO  {NatTestLauncher} waiting for nat
[14:52:08,987] WARN  {CroupierComp} <oid:0,nid:193.10.67.178:30001<2>> no partners - not shuffling
[14:52:08,987] INFO  {NatTestLauncher} nat started with:193.10.67.178:30001<2>OP
[14:52:08,990] INFO  {NatTestComp} 193.10.67.178:30001<2>OPinitiating
[14:52:08,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPstarting
[14:52:10,993] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:11,032] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:11,033] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:11,078] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:12,989] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:12,990] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:12,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:12,992] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[]
[14:52:12,993] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[]
[14:52:12,993] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinging from:193.10.67.178:30001<2>OP to:193.10.67.178:30000<1>OP
[14:52:12,994] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@71e54fabfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:12,997] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:12,997] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,016] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@6bb15f90from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:13,016] INFO  {NatTestComp} 193.10.67.178:30000<1>OPping from:193.10.67.178:30001<2>OP on:193.10.67.178:30000<1>OP
[14:52:13,017] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,017] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Pong@46e11dd2from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,018] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Pong@7d44ba4cfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,018] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpong from:193.10.67.178:30000<1>OP on:193.10.67.178:30001<2>OP
[14:52:13,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:13,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:13,039] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[]
[14:52:13,041] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[]
[14:52:13,041] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinging from:193.10.67.178:30000<1>OP to:193.10.67.178:30001<2>OP
[14:52:13,042] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Ping@2fbcde2cfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,045] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,046] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Ping@6a52c122from:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:13,046] INFO  {NatTestComp} 193.10.67.178:30001<2>OPping from:193.10.67.178:30000<1>OP on:193.10.67.178:30001<2>OP
[14:52:13,047] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:13,047] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:se.sics.nattest.msg.NatTestMsg$Pong@7f22afe7from:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:13,049] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:13,050] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:se.sics.nattest.msg.NatTestMsg$Pong@5d56f08dfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:13,050] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpong from:193.10.67.178:30001<2>OP on:193.10.67.178:30000<1>OP
[14:52:14,990] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:14,990] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:14,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:14,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:52:14,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:52:14,996] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:14,997] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:15,009] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:15,036] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:15,036] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:15,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:15,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:15,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:52:15,039] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:15,040] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:15,044] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:16,990] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:16,990] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:16,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:16,992] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:52:16,993] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:52:17,012] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:17,013] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:17,016] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:17,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:17,039] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:17,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:17,040] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:17,040] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:52:17,044] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:17,045] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:17,048] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:18,993] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:18,993] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:18,994] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:18,995] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:52:18,995] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:52:18,998] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:18,999] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:19,000] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:19,036] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:19,036] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:19,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:19,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:19,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:52:19,039] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:19,040] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:19,053] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:20,990] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:20,991] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:20,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:20,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:52:20,992] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:52:20,993] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:20,996] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:20,998] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:21,036] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:21,036] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:21,036] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:21,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:21,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:52:21,039] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:21,039] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:21,041] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:22,993] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:22,993] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:22,994] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:22,994] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:52:22,995] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:52:22,996] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:22,996] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:22,999] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:23,035] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:23,036] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:23,037] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:23,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:23,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:52:23,039] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:23,041] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:23,044] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:24,991] INFO  {NatTestComp} 193.10.67.178:30001<2>OPreceived public:[<193.10.67.178:30000<1>OP:0>], private:[]
[14:52:24,992] INFO  {NatTestComp} 193.10.67.178:30001<2>OPnat:OP
[14:52:24,992] INFO  {NatTestComp} 193.10.67.178:30001<2>OPpinged:[OP]
[14:52:24,992] INFO  {NatTestComp} 193.10.67.178:30001<2>OPponged:[OP]
[14:52:24,991] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:24,994] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:24,994] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:24,996] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:25,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:25,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:25,038] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:25,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:25,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
[14:52:25,040] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding incoming:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:25,041] WARN  {NatTraverserComp} 193.10.67.178:30001<2> forwarding outgoing:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:25,043] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding incoming:ShuffleResponsefrom:193.10.67.178:30001<2>OPto:193.10.67.178:30000<1>OP
[14:52:27,038] INFO  {NatTestComp} 193.10.67.178:30000<1>OPreceived public:[<193.10.67.178:30001<2>OP:0>], private:[]
[14:52:27,038] WARN  {NatTraverserComp} 193.10.67.178:30000<1> forwarding outgoing:ShuffleRequestfrom:193.10.67.178:30000<1>OPto:193.10.67.178:30001<2>OP
[14:52:27,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPnat:OP
[14:52:27,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPpinged:[OP]
[14:52:27,039] INFO  {NatTestComp} 193.10.67.178:30000<1>OPponged:[OP]
